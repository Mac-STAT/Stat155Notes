```{r setup4, echo=FALSE}
library(stringr)
library(infer)
library(nycflights13)
library(broom)
library(dplyr)
library(ggplot2)
library(stringr)
library(rvest)
library(mosaicData) 
library(ggmosaic)
library(NHANES)
library(mosaic)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
```

# Random Variability

Up until this point, we have thought about 

1. Data collection process (sampling and study design) and Data Quality (issues of bias)
2. Data visualization (the first step of any data analysis)
3. Modeling (to explain observed variation)

Throughout the past three chapters, we have also sprinkled in the idea that **the sample we observe is just one random representation of the true population or phenomenon.** Therefore, any numerical summary of the sample, any **statistic**, would be an estimate the true numerical summary of the population, the corresponding unknown **parameter**.


If we could repeat the random sampling process, each sample we would get would be slightly different. The individual composition would differ every time. Sometimes we would randomly over-represent one group people and another time we would randomly over-represent another group of people, just by chance. The statistic (e.g. a mean, a median, a regression coefficient) that we calculate would change slightly for every sample. 

If we could repeat the randomization process in an experiment, each treatment group would be slightly different. The individual composition of the cases in the treatment and control groups would differ every time. Sometimes we would randomly over-represent one group of people in the treatment group, and another time we would randomly over-represent another group of people in the treatment group, just by chance. The statistic that we calculate and compare between groups (e.g. a difference in means, a difference in medians, a regression coefficient) would change slightly for every reshuffling of individuals. 

This is the idea of **random variability** due to random sampling or randomization, typically. The sample composition varies and therefore, the statistics that we calculate vary.

Let's explore this concept a bit more before we formally talk about probability and chance. 

## Random Sampling from a Population

The data set we will work with contains ALL flights leaving New York City in 2013. This data represents a full census of the target population of flights leaving NYC in a particular year. 

We'll start by creating two new variables, `season` defined as winter (Oct - March) or summer (April - Sept) and `day_hour` defined as morning (midnight to noon) or afternoon (noon to midnight).

```{r}
data(flights)
flights <- flights %>% 
    na.omit() %>%
    mutate(season = case_when(
      month %in% c(10:12, 1:3) ~ "winter",
      month %in% c(4:9) ~ "summer"
    )) %>% 
    mutate(day_hour = case_when(
      between(hour, 1, 12) ~ "morning",
      between(hour, 13, 24) ~ "afternoon"
    )) %>% 
    select(arr_delay, dep_delay, season, day_hour, origin, carrier)
```

Since we have the full population, we could just describe the flights that happened. Having data on the full population is very rare in practice. Instead, we are going to use this population to help us think about sampling variability.

Let's take one random sample of 100 flights from the data set, using a simple random sampling strategy. Let's look at the arrival delay (in minutes) `arr_delay` with a histogram and calculate the median and mean arrival delay.

```{r}
flights_samp1 <- flights %>% 
    sample_n(size = 100) 

flights_samp1 %>% 
    ggplot(aes(x = arr_delay)) +
    geom_histogram() +
    theme_minimal()

flights_samp1 %>%
    summarize(medians = median(arr_delay), means = mean(arr_delay))
```

```{block type="reflect"}
At this point, we haven't looked at the entire population of flights. Based on a sample of 100 flights, what do you think the distribution of arrival delays looks like for the entire population? Shape? Center? Spread?
```

Now, let's take another random sample of 100 flights from the full population of flights.

```{r}
flights_samp2 <- flights %>% 
    sample_n(size = 100) 

flights_samp2 %>% 
    ggplot(aes(x = arr_delay)) +
    geom_histogram() +
    theme_minimal()

flights_samp2 %>%
    summarize(medians = median(arr_delay), means = mean(arr_delay))
```

```{block type="reflect"}
How does the second sample differ from the first sample? What do they have in common?
```

We could keep the process going. Take a sample of 100 flights, look at the histogram, and calculate the median and mean. Repeat many, many times. 

We can add a little bit of code to help us simulate this sampling 1000 times and calculate the median and mean for each sample of 100 flights. 

```{r}
sim_data <- mosaic::do(1000)*( 
    flights %>% 
      sample_n(size = 100) %>%  # Generate samples of 100 flights
      summarize(medians = median(arr_delay), means = mean(arr_delay)) # Calculate the median and mean
)
```

Now we have 1000 medians and 1000 means, each corresponding to a sample median and sample mean of 100 random flights from the population. Let's summarize and visualize this simulation.

```{r}
# Summarize
summary_sim <- sim_data %>% 
  summarize(mean_medians = mean(medians), 
    mean_means = mean(means), 
    sd_medians = sd(medians), 
    sd_means = sd(means))

# Visualize
sim_data %>% 
  ggplot(aes(x = medians)) +
  geom_histogram(bins = 15) +
  geom_vline(data = summary_sim, aes(xintercept = mean_medians), color = "red") +
  labs(title = "Sampling distribution of the sample median\nfrom a sample of 100 flights") +
  theme_minimal()

# Visualize
sim_data %>% 
  ggplot(aes(x = means)) +
  geom_histogram(bins = 15) +
  geom_vline(data = summary_sim, aes(xintercept = mean_means), color = "red") +
  labs(title = "Sampling distribution of the sample mean\nfrom a sample of 100 flights") +
  theme_minimal()
```

These histograms estimate the **sampling distribution** of sample median arrival delay and the **sampling distribution** of sample mean arrival delay, both of which describe the variability in the sample statistic across all possible random samples from the population. 

```{block type="reflect"}
Describe the shape, center, and spread of the sampling distribution for the sample mean.
```

### IRL: Bootstrapping 

In real life (IRL), we don't have a full target population from which we can repeatedly draw samples. We only have a sample that was already drawn from the larger target population. 

To get a sense of the sampling variability, we could try to mimic this process using our best stand-in for the population, our sample. We will call the sample our "fake population" for the moment. This process of resampling our sample is called **bootstrapping**.

**1. Generate**

To generate the different random samples of the same size (100 flights) from our "fake population", we have to draw sample of 100 flights WITH REPLACEMENT, meaning that we have to put a flight back into the pool after drawing them out. 

```{block type="reflect"}
What would happen if we drew WITHOUT REPLACEMENT?
```

**2. Calculate**

In our simulation above, we calculated the median and mean arrival delay. In theory, we could calculate any numerical summary of data (e.g. the mean, median, SD, 25th percentile, etc.)

```{r}
boot_data <- mosaic::do(1000)*( 
    flights_samp1 %>% # Start with sample
      sample_frac(replace = TRUE) %>%  # Generate by resampling with replacement
      summarize(medians = median(arr_delay), means = mean(arr_delay))  # Calculate
)
```

**3. Summarize**

Let's summarize these 1000 medians and 1000 means generated from resampling (with replacement) from our sample (our "fake population").

```{r}
# Summarize
summary_boot <- boot_data %>% 
    summarize(mean_medians = mean(medians), 
      mean_means = mean(means), 
      sd_medians = sd(medians), 
      sd_means = sd(means))
summary_boot
```

Let's compare this to the summaries from the simulation from the population.

```{r}
summary_sim
```

They won't be exactly the same, but they should be of roughly similar magnitude. 

**4. Visualize**

Let's visualize these 1000 medians and 1000 means generated from resampling (with replacement) from our sample (our "fake population").

```{r}
# Visualize
boot_data %>% 
    ggplot(aes(x = medians)) +
    geom_histogram(bins = 15) +
    geom_vline(data = summary_boot, aes(xintercept = mean_medians), color = 'red') +
    labs(title = "Bootstrap sampling distribution of the sample median") +
    theme_minimal()

# Visualize
boot_data %>% 
    ggplot(aes(x = means)) +
    geom_histogram(bins = 15) +
    geom_vline(data = summary_boot, aes(xintercept = mean_means), color = 'red') +
    labs(title = "Bootstrap sampling distribution of the sample mean") +
    theme_minimal()
```

Let's compare this to the visuals from the simulation from the population.

```{r}
# Visualize
sim_data %>% 
    ggplot(aes(x = medians)) +
    geom_histogram(bins = 15) +
    geom_vline(data = summary_sim, aes(xintercept = mean_medians), color = 'red') +
    labs(title = "Sampling distribution of the sample median\nfrom a sample of 100 flights") +
    theme_minimal()

# Visualize
sim_data %>% 
    ggplot(aes(x = means)) +
    geom_histogram(bins = 15) +
    geom_vline(data = summary_sim, aes(xintercept = mean_means), color = 'red') +
    labs(title = "Sampling distribution of the sample mean\nfrom a sample of 100 flights") +
    theme_minimal()
```

The process of resampling from our sample is called **bootstrapping**, and it is becoming the one of main computational tools for estimating sampling variability in Statistics. 

```{block type="reflect"}
How well does bootstrapping do in mimicking the simulations from the population? What could we change to improve bootstrap's ability to mimic the simulations?
```

This is a really important concept in Statistics! We'll return to the ideas of sampling variability and bootstrapping throughout the rest of the course. 

```{block type="reflect"}
What do you think the mean arrival delay is in the population? If you had to give an interval of plausible values for the population mean, what range would you give? Why?
```


## Randomization into Groups

We have been thinking about arrival delays in general. Let's move now to comparing arrival delays between groups. If you were planning a trip, you may be able to choose between two flights that leave at different times of day. Do morning flights have shorter arrival delays on average than afternoon flights? If so, book the early flight!

Let's look at the data! We use a random sample of 500 flights from the population to investigate this question.

```{r}
flights_samp500 <- flights %>% 
    sample_n(size = 500) 
```

Let's summarize and visualize the relationship between hour of the day (morning or afternoon) and the arrival delay.

```{r}
flights_samp500 %>%
    group_by(day_hour) %>%
    summarize(median = median(arr_delay), mean = mean(arr_delay))

flights_samp500 %>%
    ggplot(aes(x = day_hour, y = arr_delay)) +
    geom_boxplot() +
    theme_minimal()
```

```{block type="reflect"}
Based solely on the visual and numerical summary, are arrival delays shorter in the morning than in the afternoon?
```


We don't know the exact reason why some flights were scheduled in the morning or the afternoon and why one flight might be delayed (it's probably due to a complex combination of factors). 

If there were **no difference** in arrival delays between morning and afternoon flights, then it wouldn't matter whether a flight left in the morning or afternoon. That is, the `day_hour` variable would be irrelevant to the arrival delay `arr_delay`. If that were true, then we could reshuffle the values of `day_hour` and it wouldn't change our conclusions.

We want to compare the mean arrival delays in morning flights and in afternoon flights. Wouldn't it be great if we could see how the mean arrival delays might change if we shuffled the flights around from the "morning" group to "afternoon" group, randomly?

In fact, wouldn't it be great if we could look at every permutation of flights between two groups?

### IRL: Randomization Tests

In real life, we don't often consider every possible permutation (reshuffling of group members) due to the immensely large number of permutations. However, we can randomly reshuffle flights about 1000 times to try to approximate many permutations. Such a procedure is called a **randomization or permutation procedure**.

**1. Hypothesis**

Our **null hypothesis** (a hypothesis that is conservative) is that there is no relationship between time of day and the arrival delay. 

**2. Generate**

We can generate 1000 new data sets based on randomly reshuffling the labels of `day_hour`. For each of these data sets, we calculate the difference in mean arrival delay between morning and afternoon groups. 

```{r}
require(infer)
null_dist <-  flights_samp500 %>% 
    specify(arr_delay ~ day_hour) %>%
    hypothesize(null = "independence") %>% # Hypothesize
    generate(reps = 1000, type = "permute") %>% # Generate permutations
    calculate(stat = "diff in means", order = c("morning", "afternoon"))
```

**3. Visualize**

The histogram below shows the histogram of differences in means if the null hypothesis were true. The vertical line shows the observed difference in means. 

```{r}
obs <- flights_samp500 %>% 
    specify(arr_delay ~ day_hour) %>%
    calculate(stat = "diff in means", order = c("morning", "afternoon"))

null_dist %>% 
    ggplot(aes(x = stat)) +
    geom_histogram() + 
    geom_vline(data = obs, aes(xintercept = stat), color = "red") +
    theme_minimal()
```

```{block type="reflect"}
Do you think that the mean arrival delay is different for morning and afternoon? Is the observed difference in means likely to have occurred if there were no relationship?
```

We will return to the ideas of testing hypotheses later in the course.
