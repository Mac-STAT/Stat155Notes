```{r setup5, echo=FALSE}
library(stringr)
library(infer)
library(nycflights13)
library(broom)
library(dplyr)
library(ggplot2)
library(stringr)
library(rvest)
library(mosaicData) 
library(ggmosaic)
library(NHANES)
library(mosaic)
knitr::opts_chunk$set(echo = FALSE)
```

# Randomness and Probability

Recall the model we built to predict home price as a function of square footage and fireplaces. 

```{r echo=TRUE}
homes <- read.delim("http://sites.williams.edu/rdeveaux/files/2014/09/Saratoga.txt")
homes <- homes %>%
  mutate(AnyFireplace = Fireplaces > 0)
homes %>%
    ggplot(aes(x = Living.Area, y = Price, color = AnyFireplace)) + 
    geom_point(alpha = 0.25) +
    geom_smooth(method = "lm") +
    theme_minimal()
```

To allow for different slopes among home with and without a fireplace, we used an interaction term between Living.Area and AnyFireplace. Based on our sample, we observed a difference in the slopes of $26.85 per square foot. But is this true for the larger population of homes? Is each square foot worth exactly $26.85 more, on average, in homes with a fireplace than in homes without a fireplace?

```{r echo=TRUE}
lm.home3 <- lm(Price ~ AnyFireplace*Living.Area, data = homes)
tidy(lm.home3)
```

Probably not. In fact, our sample is just one random sample from the larger population of homes in upstate New York. If we had gotten a slightly different sample of homes, then we would have different estimates for each of the regression coefficients. We explored this sampling variation in Chapter 4 using bootstrapping.

Let's connect our goals to the terms: **statistic** and **parameter**. The interaction coefficient of $26.85 is a **statistic**. It (as well as the other coefficient estimates) is a numerical summary of our data that was estimated from a **sample**. If we had a census, a full set of data on all homes in upstate New York, we could fit the same linear regression model. The coefficient estimates given to us by R would represent population **parameters** because they are computed from the whole population, rather than a sample. By understanding **how much** statistics vary from sample to sample, we can start to **quantify the amount of uncertainty** in our estimates. Because the process of obtaining a sample is a type of random chance, we will spend some time discussing formal probability.

This chapter briefly discusses the theory of formal probability so that we have terminology and basic concepts to understand and discuss random events. This framework provides a way of thinking about **uncertainty**, **random variability**, and **average behavior in the long run.**

A **random process** or **random event** is any process/event whose outcome is governed by chance. It is any process/event that cannot be known with certainty. Examples range from the outcome of flipping a coin to estimating model parameters from randomly selected samples.

We've used the term "chances" up until now, and we defined that the chance of an event is between 0 and 1. We are now going to use "probability" as an equivalent word for "chance". Thus, the probability of an event will be between 0 and 1.

For a much more in-depth discussion of probability (calculus-based), take MATH 354 (Probability). 

## Three Types of Probability

```{block type="reflect"}
What is the probability of getting a 1 from a six-sided die? How do you know this? How can you justify that number?
```

There are three types of probability.

1. **Empirical Probability:** If you could repeat a random process over and over again, we'd get a sense of the possible outcomes and their associated probabilities by calculating their relative frequency in the long run. If you repeatedly tossed a balanced die, then the relative frequency of 1's after tossing the die MANY times would be the empirical probability. If you repeatedly got a sample of 100 people, the relative frequency of estimated odds ratios below 1 would be the empirical probability of getting an odds ratio below 1. 

2. **Theoretical Probability:** If you don't have time to toss a die a million times, you could calculate probabilities based on mathematical theory and assumptions. When tossing a die, you would assume that each side is equally likely to land face-up. Thus the chance of rolling a 1, is 1/6 for a six-sided die.

```{block type="reflect"}
What is the probability you'll get an A in this class? What does that number represent? How can you justify that number?
```

3. **Subjective Probability:** If you use a number between 0 and 1 (100%) to reflect your uncertainty in an outcome (rather than based on empirical evidence or mathematical theory), then you are using subjective probability.

In this class, we'll focus on theoretical and empirical probability. In particular, we will use computational tools to estimate empirical probabilities using simulations (such as bootstrapping and randomization tests) and mathematical tools to estimate theoretical probabilities. 

## Probability Rules

In theoretical probability, we need to define a few terms and set some rules for working with probabilities (known as axioms).

The **sample space**, $S$, is the set of all possible outcomes of a random process.

- Example: If you flip two coins (one side Heads and one side Tails), then the sample space contains four possible outcomes: Heads and Heads (HH), Heads and Tails (HT), Tails and Heads (TH), and Tails and Tails (TT), $S = \{HH,HT,TH,TT\}$.

A subset of outcomes is called an **event**, $A$. 

- Example: If you flip two coins, an event $A$ could be that exactly one of the coins land Heads, $A = \{HT,TH\}$.

For events $A$ and $B$ and sample space $S$, the probability of an event $A$, notated as $P(A)$, follows the rules below:

- Rule 1: $0\leq P(A)\leq 1$ (probability has to be between 0 and 1)
- Rule 2: $P(S) = 1$ (one of the possible outcomes has to happen)
- Rule 3: $P(\text{not }A) = 1 - P(A)$ (if we know the chance of something happening, we also know that chance it doesn't happen)
- Rule 4: $P(A\text{ or }B) = P(A) + P(B)$ if $A$ and $B$ are disjoint events.
  - $A$ and $B$ are **disjoint** if $A$ occuring prevents $B$ from occurring (they both can't happen at the same time).
- Rule 4*: $P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and } B)$ in general
- Rule 5: $ P(A\text{ and }B) = P(A)\times P(B)$ if $A$ and $B$ are independent.
  - $A$ and $B$ are **independent** if $B$ occurring doesn't change the probability of $A$ occurring.
- Rule 5*: $P(A\text{ and }B) = P(A \mid B)P(B) = P(B \mid A)P(A)$.
  - The **conditional probability** of A **given** that event B occurs, $P(A \mid B)$, is equal to the probability of the joint event (A and B) divided by the probability of B.
$$ P(A \mid B) = \frac{P(A \text{ and } B)}{P(B)} $$
  - Intuition: Given that $B$ happened, we focus on the subset of outcomes in $S$ in which $B$ occurs and then figure out what the chance of $A$ happening within that subset. 

For more details on theoretical probability, please see Appendix A. This material is optional but available for those of you who want to understand the mathematical reasoning behind the rest of the chapter.

### Diagnotic Testing and Probability

Let's start by taking a moment to consider a recent [Washington Post article](https://www.washingtonpost.com/news/posteverything/wp/2018/10/05/feature/doctors-are-surprisingly-bad-at-reading-lab-results-its-putting-us-all-at-risk/?utm_term=.73d08eefca3c) that discusses the role of probability in medical diagnostics. Before you read the whole article, consider a question.

```{block, type="reflect"}
Say that Disease X has a prevalence of 1 in 1,000 (meaning that 1 out of every 1,000 people will have it). The test to detect Disease X has a false-positive rate of 5 percent (meaning that out of every 100 subjects who do not have Disease X, 5 will falsely test positive for it). If a patient's test result comes back positive, what is the probability that this patient actually has the disease?
```

If you said the probability is 95%, then you are wrong, but almost half of the doctors surveyed in 2014 thought exactly the same thing.

We can use the rules of probability to get a sense of what the desired probability actually is. We want to know the probability that they have the disease GIVEN that they got a positive test result, $P(D \mid +)$ where $D$ stands for disease and $+$ stands for positive test result.

Based on the definition of conditional probability, we must consider only those that got a positive test result back and look at the proportion of them that have the disease. In mathematical notation, that is equal to

$$P(D \mid +) = \frac{P(D \text{ and } +)}{P(+)}$$

What information were we given again?

- The prevalence of the disease is 1 in 1,000, so $P(D) = 1/1000$. Using Rule 3, the probability of no disease is $P(\text{ no }D) = 999/1000$. In 1000 people, 1 will actually have the disease and 999 won't have the disease.

- The false-positive rate is 5 percent, so given you don't have the disease, the probability of getting a false positive is $P(+ \mid\text{ no } D) = 0.05$. So of the 999 that don't have the disease, about $0.05\times 999 = 49.95$ (about 50) of them will get a false positive test result.

- While it is not stated, most medical tests have a fairly high accuracy in catching the disease so $P(+ \mid D) = 0.99$. Therefore, the 1 person who actually has the disease will most likely get a positive test result back ($0.99*1 = 0.99$).

Remember that our interest is in $P(D \mid +)$. By the definition of conditional probability, we consider only those with positive test results (about 50 who are disease free and 1 who has the disease). So the probability of actually having the disease GIVEN a positive test result is about 1/51 = 0.019.

In mathematical notation, that looks like this

$$
\begin{align*}
P(D \mid +) &= \frac{P(D \text{ and } +)}{P(+)} \\
&= \frac{P(D \text{ and } +)}{P(+ \text{ and } D) + P(+ \text{ and no } D)} \\
&= \frac{P(+ \mid D) P(D)}{P( + \mid D) P(D) + P( + \mid \text{ no }D) P(\text{no }D)} \\
&= \frac{0.99*1/1000}{0.99*1/1000 + 0.05*999/1000} \\
&= \frac{0.99*1}{0.99*1 + 0.05*999}
\end{align*}
$$

The first expression above ($P(D \mid +) &= \frac{P(D \text{ and } +)}{P(+)}$) is often called **Bayes' Rule**. The important idea to take from this is that what we condition on can make a big difference in the resulting probability.

Take some time to read the full [Washington Post article](https://www.washingtonpost.com/news/posteverything/wp/2018/10/05/feature/doctors-are-surprisingly-bad-at-reading-lab-results-its-putting-us-all-at-risk/?utm_term=.73d08eefca3c).

### Court Arguments and Probability

The concept of conditional probability also plays an important role in the judicial system in the U.S. The basis of the judicial system is the idea of "innocent until proven guilty". Assuming that the defendant is innocent, what are the changes of having this evidence? That is, evidence is presented to jurors as the conditional probability: $P(\text{ evidence } \mid \text{ innocent })$.

Unfortunately, many prosecutors try to make the wrong argument by flipping the conditional probability, whether maliciously or due to a lack of statistical knowledge. They sometimes mistakenly try to argue that it is unlikely that a person is innocent given the evidence that is available, $P(\text{ innocent } \mid \text{ evidence })$. This can be dangerous if a prosecutor argues that since $P(\text{ evidence } \mid \text{ innocent }) = 1/\text{1 million}$ to argue that $P(\text{ innocent } \mid \text{ evidence }) = 1/\text{1 million}$.

This is known as the prosecutor's fallacy. You can read more about it [here](https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy).



## Random Variable

With a basic understanding of theoretical probability rules, we can introduce the most important concept from probability for our uses in this class.

A **random variable** ($X$) is variable whose outcome (the value it takes) is governed by chance. It is a variable (something capable of taking different values) whose value is random. Examples include:

- $X =$ age of the next person to walk into the building
- $X =$ the number the lands face up on a balanced 6-sided die

When considering data analysis and modeling, the random variables we will be thinking about will be estimated regression coefficients, estimate odds ratios, etc. Why are these random variables? Because their values depend on the random samples that we draw. To establish our understanding, let's start with a simple example.

You are going to flip a fair coin 3 times (the coin has 2-sides, we'll call one side Heads and the other Tails).

- Assume there are only 2 possible outcomes and $P(\text{Heads}) = P(\text{Tails}) = 0.5$. (The coin can't land on its side).
- Below are three possible random variables based on the same random process (flipping a 2-sided coin 3 times):

- Example 1: $X =$ the number of heads in 3 coin flips
- What are the possible values of $X$? 0, 1, 2, or 3.

- Example 2: Say I give you 3 dollars for each Head
- $Y =$ the amount of money won from 3 coin flips, $Y = 3*X$
- The possible values of $Y$ are 0, 3, 6, or 9.

- Example 3: $Z =$ the number of heads on the last of the 3 coin flips
- The possible values are 0 or 1.


## Probability Models

A **probability model** for a random variable $X$ gives the possible values of $X$ and the associated probabilities. 

- What is the probability model for $X$: the number of heads in 3 coin flips?

$P(X = 0) = P(\text{three tails}) =  0.5^3$ (using Rule 5)
$P(X = 1) = P(\text{HTT or THT or TTH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(X = 2) = P(\text{HHT or HTH or THH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(X = 3) = P(\text{three heads}) = 0.5^3$ (using Rule 5)

- What is the probability model for $Y= 3*X$?

$P(Y = 0) = P(\text{three tails}) =  0.5^3$ (using Rule 5)
$P(Y = 3) = P(\text{HTT or THT or TTH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(Y = 6) = P(\text{HHT or HTH or THH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(Y = 9) = P(\text{three heads}) = 0.5^3$ (using Rule 5)

- What about $Z$?

$P(Z = 0) = P(\text{HHT or TTT or HTT or THT}) =  4*0.5^3 = 0.5$ (using Rule 4 & 5)
$P(Z = 1) = P(\text{HHH or TTH or HTH or THH}) = 4*0.5^3 = 0.5$ (using Rule 4 & 5)

For most situations in our class, we won't be using the probability rules to calculate chances by hand. 

Rather, we will use a **named probability model** such that the we can calculate probabilities for particular values of the random variable using either:

- a **probability mass function (pmf)** (finite number of possible values) or 
- a **probability density function (pdf)** (infinite number of possible values)

### Using probability mass functions

Let's say that we are working with a random variable $X$ that represents the result of spinning the arrow on a spinner that has 3 regions labeled 1, 2, and 3. $X$ can only takes the values 1, 2, or 3. The probability mass function (pmf) for X gives the probabilities that $X=1$, $X=2$, and $X=3$ which are determined by the relative areas of the regions on the spinner. The pmf for X is frequently denoted as $p(x)$, which is shorthand for $P(X = x)$. Based on the construction of the spinner, the pmf can be denoted as below:

|    $x$ |  1  |  2  |  3  |
|-------:|:---:|:---:|:---:|
| $p(x)$ | 0.4 | 0.5 | 0.1 |

The first row indicates the values that $X$ can take. The second row indicates the associated probabilities, the values of the probability mass function. Note that this row adds up to 1 because one of these 3 outcomes must happen.

We can use the pmf and the probability rules introduced earlier to calculate probabilities of different events.

Example 1: $P(X = 1 \text{ or } 2)$

Because the events $X = 1$ and $X = 2$ are disjoint (mutually exclusive/can't happen simultaneously), this probability is equal to $P(X = 1) + P(X = 2) = 0.4 + 0.5 = 0.9$. (Rule 4)

Example 2: $P(X \neq 1)$

By Rule 3, $P(X \neq 1) = 1 - P(X = 1) = 1 - 0.4 = 0.6$. Another way to arrive at this would be to see that $P(X \neq 1) = P(X = 2 \text{ or } 3) = P(X = 2) + P(X = 3) = 0.5 + 0.1$.

### Using probability density functions


### Expected value and variance

Two important properties of a random variable $X$ are its **expected value** and **variance**.




- Expected Value and Variance as concepts, not as theory
- Put in context of sampling variability (mean and sd of the sampling distribution) and variability from randomization assignment



##Bernoulli/Binomial

- Tie to Logistic regression
- E(x) = p or E(x) = np or E(x/n) = p
- tie to sampling variability and the disease we talk about previously
- show the pmf graphically (show what it does when n get large)

##Normal
- Many Normal curve (each with its own mean and sd)
- Area under curve as it relates to 68-95-99.7 rule
- relate to z-score
- Big IDEA: +- 2SD


##Sampling Distribution and CLT
- Connecting CLT (NORMAL) and bootstrapping
- SE (estimate of RV SD), z-scores ( value - E(X) / SE)




