<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.10 Logistic Regression | Stat 155 Notes</title>
  <meta name="description" content="This includes notes for STAT 155 at Macalester College." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="3.10 Logistic Regression | Stat 155 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This includes notes for STAT 155 at Macalester College." />
  <meta name="github-repo" content="bcheggeseth/Stat155Notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.10 Logistic Regression | Stat 155 Notes" />
  
  <meta name="twitter:description" content="This includes notes for STAT 155 at Macalester College." />
  

<meta name="author" content="Macalester Statistics Faculty (Heggeseth, Myint)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-linear-regression.html">
<link rel="next" href="random-variability.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"Stat 155 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="data-collection-and-quality.html"><a href="data-collection-and-quality.html"><i class="fa fa-check"></i><b>1</b> Data Collection and Quality</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-data.html"><a href="what-is-data.html"><i class="fa fa-check"></i><b>1.1</b> What is Data?</a></li>
<li class="chapter" data-level="1.2" data-path="data-context.html"><a href="data-context.html"><i class="fa fa-check"></i><b>1.2</b> Data Context</a></li>
<li class="chapter" data-level="1.3" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>1.3</b> Sampling</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sampling.html"><a href="sampling.html#sampling-bias"><i class="fa fa-check"></i><b>1.3.1</b> Sampling Bias</a></li>
<li class="chapter" data-level="1.3.2" data-path="sampling.html"><a href="sampling.html#random-sampling"><i class="fa fa-check"></i><b>1.3.2</b> Random Sampling</a></li>
<li class="chapter" data-level="1.3.3" data-path="sampling.html"><a href="sampling.html#nonresponse-bias"><i class="fa fa-check"></i><b>1.3.3</b> Nonresponse bias</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="information-bias.html"><a href="information-bias.html"><i class="fa fa-check"></i><b>1.4</b> Information bias</a></li>
<li class="chapter" data-level="1.5" data-path="study-design.html"><a href="study-design.html"><i class="fa fa-check"></i><b>1.5</b> Study Design</a></li>
<li class="chapter" data-level="1.6" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>1.6</b> Causal Inference</a></li>
<li class="chapter" data-level="1.7" data-path="ethical-considerations.html"><a href="ethical-considerations.html"><i class="fa fa-check"></i><b>1.7</b> Ethical Considerations</a></li>
<li class="chapter" data-level="1.8" data-path="major-takeaways.html"><a href="major-takeaways.html"><i class="fa fa-check"></i><b>1.8</b> Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="visualizing-data.html"><a href="visualizing-data.html"><i class="fa fa-check"></i><b>2</b> Visualizing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="good-visualization-principles.html"><a href="good-visualization-principles.html"><i class="fa fa-check"></i><b>2.1</b> Good Visualization Principles</a></li>
<li class="chapter" data-level="2.2" data-path="brief-intro-to-r.html"><a href="brief-intro-to-r.html"><i class="fa fa-check"></i><b>2.2</b> Brief Intro to R</a><ul>
<li class="chapter" data-level="2.2.1" data-path="brief-intro-to-r.html"><a href="brief-intro-to-r.html#basic-syntax"><i class="fa fa-check"></i><b>2.2.1</b> Basic Syntax</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="anatomy-of-a-ggplot-command.html"><a href="anatomy-of-a-ggplot-command.html"><i class="fa fa-check"></i><b>2.3</b> Anatomy of a ggplot command</a></li>
<li class="chapter" data-level="2.4" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html"><i class="fa fa-check"></i><b>2.4</b> One Categorical Variable</a><ul>
<li class="chapter" data-level="2.4.1" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html#bar-plot"><i class="fa fa-check"></i><b>2.4.1</b> Bar Plot</a></li>
<li class="chapter" data-level="2.4.2" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html#pie-chart"><i class="fa fa-check"></i><b>2.4.2</b> Pie Chart</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html"><i class="fa fa-check"></i><b>2.5</b> Two Categorical Variables</a><ul>
<li class="chapter" data-level="2.5.1" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#side-by-side-bar-plot"><i class="fa fa-check"></i><b>2.5.1</b> Side by Side Bar Plot</a></li>
<li class="chapter" data-level="2.5.2" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#stacked-bar-plot"><i class="fa fa-check"></i><b>2.5.2</b> Stacked Bar Plot</a></li>
<li class="chapter" data-level="2.5.3" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#stacked-bar-plot-relative-frequencies"><i class="fa fa-check"></i><b>2.5.3</b> Stacked Bar Plot (Relative Frequencies)</a></li>
<li class="chapter" data-level="2.5.4" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#mosaic-plot"><i class="fa fa-check"></i><b>2.5.4</b> Mosaic Plot</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html"><i class="fa fa-check"></i><b>2.6</b> One Quantitative Variable</a><ul>
<li class="chapter" data-level="2.6.1" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#histogram"><i class="fa fa-check"></i><b>2.6.1</b> Histogram</a></li>
<li class="chapter" data-level="2.6.2" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#center"><i class="fa fa-check"></i><b>2.6.2</b> Center</a></li>
<li class="chapter" data-level="2.6.3" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#boxplot"><i class="fa fa-check"></i><b>2.6.3</b> Boxplot</a></li>
<li class="chapter" data-level="2.6.4" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#spread"><i class="fa fa-check"></i><b>2.6.4</b> Spread</a></li>
<li class="chapter" data-level="2.6.5" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#intro-zscore"><i class="fa fa-check"></i><b>2.6.5</b> Some data accounting</a></li>
<li class="chapter" data-level="2.6.6" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#z-scores"><i class="fa fa-check"></i><b>2.6.6</b> Z-scores</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="one-quantitative-variable-and-one-categorical-variable.html"><a href="one-quantitative-variable-and-one-categorical-variable.html"><i class="fa fa-check"></i><b>2.7</b> One Quantitative Variable and One Categorical Variable</a><ul>
<li class="chapter" data-level="2.7.1" data-path="one-quantitative-variable-and-one-categorical-variable.html"><a href="one-quantitative-variable-and-one-categorical-variable.html#multiple-histograms"><i class="fa fa-check"></i><b>2.7.1</b> Multiple Histograms</a></li>
<li class="chapter" data-level="2.7.2" data-path="one-quantitative-variable-and-one-categorical-variable.html"><a href="one-quantitative-variable-and-one-categorical-variable.html#multiple-boxplots"><i class="fa fa-check"></i><b>2.7.2</b> Multiple Boxplots</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html"><i class="fa fa-check"></i><b>2.8</b> Two Quantitative Variables</a><ul>
<li class="chapter" data-level="2.8.1" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#scatterplot"><i class="fa fa-check"></i><b>2.8.1</b> Scatterplot</a></li>
<li class="chapter" data-level="2.8.2" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#correlation-coefficient"><i class="fa fa-check"></i><b>2.8.2</b> Correlation Coefficient</a></li>
<li class="chapter" data-level="2.8.3" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#properties"><i class="fa fa-check"></i><b>2.8.3</b> Properties</a></li>
<li class="chapter" data-level="2.8.4" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#is-correlation-always-the-right-way-to-judge-strength"><i class="fa fa-check"></i><b>2.8.4</b> Is correlation always the right way to judge strength?</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html"><i class="fa fa-check"></i><b>2.9</b> Three or more variables</a><ul>
<li class="chapter" data-level="2.9.1" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#a-bivariate-plot"><i class="fa fa-check"></i><b>2.9.1</b> A bivariate plot</a></li>
<li class="chapter" data-level="2.9.2" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-color"><i class="fa fa-check"></i><b>2.9.2</b> Enriching with color</a></li>
<li class="chapter" data-level="2.9.3" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-shape"><i class="fa fa-check"></i><b>2.9.3</b> Enriching with shape</a></li>
<li class="chapter" data-level="2.9.4" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-size"><i class="fa fa-check"></i><b>2.9.4</b> Enriching with size</a></li>
<li class="chapter" data-level="2.9.5" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-panels"><i class="fa fa-check"></i><b>2.9.5</b> Enriching with panels</a></li>
<li class="chapter" data-level="2.9.6" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#putting-everything-together"><i class="fa fa-check"></i><b>2.9.6</b> Putting everything together</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="major-takeaways-1.html"><a href="major-takeaways-1.html"><i class="fa fa-check"></i><b>2.10</b> Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>3</b> Regression Models</a><ul>
<li class="chapter" data-level="3.1" data-path="goals-for-models.html"><a href="goals-for-models.html"><i class="fa fa-check"></i><b>3.1</b> Goals for models</a></li>
<li class="chapter" data-level="3.2" data-path="lines.html"><a href="lines.html"><i class="fa fa-check"></i><b>3.2</b> Lines</a></li>
<li class="chapter" data-level="3.3" data-path="choosing-the-best-fitting-line.html"><a href="choosing-the-best-fitting-line.html"><i class="fa fa-check"></i><b>3.3</b> Choosing the best fitting line</a><ul>
<li class="chapter" data-level="3.3.1" data-path="choosing-the-best-fitting-line.html"><a href="choosing-the-best-fitting-line.html#first-idea"><i class="fa fa-check"></i><b>3.3.1</b> First idea</a></li>
<li class="chapter" data-level="3.3.2" data-path="choosing-the-best-fitting-line.html"><a href="choosing-the-best-fitting-line.html#second-idea"><i class="fa fa-check"></i><b>3.3.2</b> Second idea</a></li>
<li class="chapter" data-level="3.3.3" data-path="choosing-the-best-fitting-line.html"><a href="choosing-the-best-fitting-line.html#third-idea"><i class="fa fa-check"></i><b>3.3.3</b> Third idea</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="least-squares.html"><a href="least-squares.html"><i class="fa fa-check"></i><b>3.4</b> Least Squares</a></li>
<li class="chapter" data-level="3.5" data-path="properties-of-least-squares-line.html"><a href="properties-of-least-squares-line.html"><i class="fa fa-check"></i><b>3.5</b> Properties of Least Squares Line</a><ul>
<li class="chapter" data-level="3.5.1" data-path="properties-of-least-squares-line.html"><a href="properties-of-least-squares-line.html#real-companies"><i class="fa fa-check"></i><b>3.5.1</b> Real companies</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>3.6</b> Interpretation</a><ul>
<li class="chapter" data-level="3.6.1" data-path="interpretation.html"><a href="interpretation.html#correlation-or-association-vs.causation"><i class="fa fa-check"></i><b>3.6.1</b> Correlation or Association vs. Causation</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>3.7</b> Evaluation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="evaluation.html"><a href="evaluation.html#prediction"><i class="fa fa-check"></i><b>3.7.1</b> Prediction</a></li>
<li class="chapter" data-level="3.7.2" data-path="evaluation.html"><a href="evaluation.html#prediction-errors"><i class="fa fa-check"></i><b>3.7.2</b> Prediction Errors</a></li>
<li class="chapter" data-level="3.7.3" data-path="evaluation.html"><a href="evaluation.html#r2"><i class="fa fa-check"></i><b>3.7.3</b> <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>3.8</b> Diagnostics</a><ul>
<li class="chapter" data-level="3.8.1" data-path="diagnostics.html"><a href="diagnostics.html#solutions-to-issues"><i class="fa fa-check"></i><b>3.8.1</b> Solutions to Issues</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>3.9</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.9.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#indicator-variables"><i class="fa fa-check"></i><b>3.9.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="3.9.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interaction-variables"><i class="fa fa-check"></i><b>3.9.2</b> Interaction Variables</a></li>
<li class="chapter" data-level="3.9.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#causation"><i class="fa fa-check"></i><b>3.9.3</b> Causation</a></li>
<li class="chapter" data-level="3.9.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#conditions-for-multiple-linear-regression"><i class="fa fa-check"></i><b>3.9.4</b> Conditions for Multiple Linear Regression</a></li>
<li class="chapter" data-level="3.9.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#is-the-difference-real"><i class="fa fa-check"></i><b>3.9.5</b> Is the Difference Real?</a></li>
<li class="chapter" data-level="3.9.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#dealing-with-non-linear-relationships"><i class="fa fa-check"></i><b>3.9.6</b> Dealing with Non-Linear Relationships</a></li>
<li class="chapter" data-level="3.9.7" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#alternative-solutions"><i class="fa fa-check"></i><b>3.9.7</b> Alternative Solutions</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>3.10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="3.10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-and-logit"><i class="fa fa-check"></i><b>3.10.1</b> Logistic and Logit</a></li>
<li class="chapter" data-level="3.10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-the-model"><i class="fa fa-check"></i><b>3.10.2</b> Fitting the Model</a></li>
<li class="chapter" data-level="3.10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation-1"><i class="fa fa-check"></i><b>3.10.3</b> Interpretation</a></li>
<li class="chapter" data-level="3.10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#prediction-1"><i class="fa fa-check"></i><b>3.10.4</b> Prediction</a></li>
<li class="chapter" data-level="3.10.5" data-path="logistic-regression.html"><a href="logistic-regression.html#model-evaluation"><i class="fa fa-check"></i><b>3.10.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="3.10.6" data-path="logistic-regression.html"><a href="logistic-regression.html#alternative-classification-models"><i class="fa fa-check"></i><b>3.10.6</b> Alternative Classification Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-variability.html"><a href="random-variability.html"><i class="fa fa-check"></i><b>4</b> Random Variability</a><ul>
<li class="chapter" data-level="4.1" data-path="random-sampling-from-a-population.html"><a href="random-sampling-from-a-population.html"><i class="fa fa-check"></i><b>4.1</b> Random Sampling from a Population</a><ul>
<li class="chapter" data-level="4.1.1" data-path="random-sampling-from-a-population.html"><a href="random-sampling-from-a-population.html#irl-bootstrapping"><i class="fa fa-check"></i><b>4.1.1</b> IRL: Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="randomization-into-groups.html"><a href="randomization-into-groups.html"><i class="fa fa-check"></i><b>4.2</b> Randomization into Groups</a><ul>
<li class="chapter" data-level="4.2.1" data-path="randomization-into-groups.html"><a href="randomization-into-groups.html#irl-randomization-tests"><i class="fa fa-check"></i><b>4.2.1</b> IRL: Randomization Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="randomness-and-probability.html"><a href="randomness-and-probability.html"><i class="fa fa-check"></i><b>5</b> Randomness and Probability</a><ul>
<li class="chapter" data-level="5.1" data-path="three-types-of-probability.html"><a href="three-types-of-probability.html"><i class="fa fa-check"></i><b>5.1</b> Three Types of Probability</a></li>
<li class="chapter" data-level="5.2" data-path="probability-rules.html"><a href="probability-rules.html"><i class="fa fa-check"></i><b>5.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="5.2.1" data-path="probability-rules.html"><a href="probability-rules.html#diagnotic-testing-and-probability"><i class="fa fa-check"></i><b>5.2.1</b> Diagnotic Testing and Probability</a></li>
<li class="chapter" data-level="5.2.2" data-path="probability-rules.html"><a href="probability-rules.html#court-arguments-and-probability"><i class="fa fa-check"></i><b>5.2.2</b> Court Arguments and Probability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="random-variable.html"><a href="random-variable.html"><i class="fa fa-check"></i><b>5.3</b> Random Variable</a></li>
<li class="chapter" data-level="5.4" data-path="probability-models.html"><a href="probability-models.html"><i class="fa fa-check"></i><b>5.4</b> Probability Models</a><ul>
<li class="chapter" data-level="5.4.1" data-path="probability-models.html"><a href="probability-models.html#using-probability-mass-functions"><i class="fa fa-check"></i><b>5.4.1</b> Using probability mass functions</a></li>
<li class="chapter" data-level="5.4.2" data-path="probability-models.html"><a href="probability-models.html#using-probability-density-functions"><i class="fa fa-check"></i><b>5.4.2</b> Using probability density functions</a></li>
<li class="chapter" data-level="5.4.3" data-path="probability-models.html"><a href="probability-models.html#expected-value-and-variance"><i class="fa fa-check"></i><b>5.4.3</b> Expected value and variance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="bernoullibinomial-model.html"><a href="bernoullibinomial-model.html"><i class="fa fa-check"></i><b>5.5</b> Bernoulli/Binomial Model</a></li>
<li class="chapter" data-level="5.6" data-path="normal-model.html"><a href="normal-model.html"><i class="fa fa-check"></i><b>5.6</b> Normal Model</a></li>
<li class="chapter" data-level="5.7" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html"><i class="fa fa-check"></i><b>5.7</b> Sampling Distribution and CLT</a><ul>
<li class="chapter" data-level="5.7.1" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html#sampling-distributions"><i class="fa fa-check"></i><b>5.7.1</b> Sampling distributions</a></li>
<li class="chapter" data-level="5.7.2" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.7.2</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html"><i class="fa fa-check"></i><b>5.8</b> Z-scores and the Student’s “t” distribution</a><ul>
<li class="chapter" data-level="5.8.1" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#gossets-work"><i class="fa fa-check"></i><b>5.8.1</b> Gosset’s Work</a></li>
<li class="chapter" data-level="5.8.2" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#beer-helps-the-field-of-statistics"><i class="fa fa-check"></i><b>5.8.2</b> Beer Helps the Field of Statistics</a></li>
<li class="chapter" data-level="5.8.3" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#student-t-model"><i class="fa fa-check"></i><b>5.8.3</b> Student T Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>6</b> Statistical Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>6.1</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="6.1.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#via-classical-theory"><i class="fa fa-check"></i><b>6.1.1</b> Via Classical Theory</a></li>
<li class="chapter" data-level="6.1.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#via-bootstrapping"><i class="fa fa-check"></i><b>6.1.2</b> Via Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html"><i class="fa fa-check"></i><b>6.2</b> Confidence Interval Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#proportion-outcome"><i class="fa fa-check"></i><b>6.2.1</b> Proportion Outcome</a></li>
<li class="chapter" data-level="6.2.2" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#mean-and-then-median"><i class="fa fa-check"></i><b>6.2.2</b> Mean and then Median</a></li>
<li class="chapter" data-level="6.2.3" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#logistic-regression-model"><i class="fa fa-check"></i><b>6.2.3</b> Logistic Regression Model</a></li>
<li class="chapter" data-level="6.2.4" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#linear-regression-model-slope-categorical-variable"><i class="fa fa-check"></i><b>6.2.4</b> Linear Regression Model Slope (Categorical Variable)</a></li>
<li class="chapter" data-level="6.2.5" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#linear-regression-model-slope-quantitative-var"><i class="fa fa-check"></i><b>6.2.5</b> Linear Regression Model Slope (Quantitative Var)</a></li>
<li class="chapter" data-level="6.2.6" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#confidence-intervals-for-prediction"><i class="fa fa-check"></i><b>6.2.6</b> Confidence Intervals for Prediction</a></li>
<li class="chapter" data-level="6.2.7" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#prediction-intervals"><i class="fa fa-check"></i><b>6.2.7</b> Prediction Intervals</a></li>
<li class="chapter" data-level="6.2.8" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#probability-theory-vs.bootstrapping"><i class="fa fa-check"></i><b>6.2.8</b> Probability Theory vs. Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6.3</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-statistics"><i class="fa fa-check"></i><b>6.3.1</b> Test statistics</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#logic-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.3.2</b> Logic of hypothesis testing</a></li>
<li class="chapter" data-level="6.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#summary-of-procedure"><i class="fa fa-check"></i><b>6.3.3</b> Summary of procedure</a></li>
<li class="chapter" data-level="6.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#testing-single-model-coefficients"><i class="fa fa-check"></i><b>6.3.4</b> Testing single model coefficients</a></li>
<li class="chapter" data-level="6.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#distributions-of-test-statistics"><i class="fa fa-check"></i><b>6.3.5</b> Distributions of test statistics</a></li>
<li class="chapter" data-level="6.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#graphical-description-of-p-values"><i class="fa fa-check"></i><b>6.3.6</b> Graphical description of p-values</a></li>
<li class="chapter" data-level="6.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-linear-regression"><i class="fa fa-check"></i><b>6.3.7</b> Example: Linear Regression</a></li>
<li class="chapter" data-level="6.3.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-logistic-regression"><i class="fa fa-check"></i><b>6.3.8</b> Example: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistical-significance-v-practical-significance.html"><a href="statistical-significance-v-practical-significance.html"><i class="fa fa-check"></i><b>6.4</b> Statistical Significance v. Practical Significance</a></li>
<li class="chapter" data-level="6.5" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>6.5</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix-a-theoretical-probability.html"><a href="appendix-a-theoretical-probability.html"><i class="fa fa-check"></i><b>7</b> Appendix A - Theoretical Probability</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stat 155 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">3.10</span> Logistic Regression</h2>
<p>If you are interested in predicting a binary categorical variable (only 2 possible outcomes), the standard linear regression models don’t apply. If you let the two outcomes be 0 and 1, you’ll never get a straight line relationship with an x variable.</p>
<p>Throughout this section, we will refer to one outcome as ‘success’ (denoted 1) and ‘failure’ (denoted 0). Depending on the context of the data, the success could be a negative thing such as ‘heart attack’ or ‘20 year mortality’.</p>
<p>We will let <span class="math inline">\(p\)</span> be the chance of success and <span class="math inline">\(1- p\)</span> be the chance of failure. We want to build a model to explain why the chance of success may be higher for one group of people in comparison to another.</p>
<div id="logistic-and-logit" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Logistic and Logit</h3>
<p>The <strong>logistic function</strong> is an S shaped curve (sigmoid curve). For our purposes, the function will take the form</p>
<p><span class="math display">\[f(x) = \frac{1}{1 + e^{b_0 +b_1x}}\]</span></p>
<p><img src="Stat155Notes_files/figure-html/unnamed-chunk-178-1.png" width="672" /></p>
<p>For any real value x, f(x) will be a value between 0 and 1. This is perfect for us since probabilities/chances should also be between 0 and 1.</p>
<p>In fact, we’ll let the chance of failure, <span class="math inline">\(1-p\)</span>, be modeled by this function.</p>
<span class="math display">\[1-p = \frac{1}{1 + e^{b_0 +b_1x}}\]</span>
<div class="math">
<p>
With a bit of algebra and rearranging terms, we can write this in terms of <span class="math inline"><span class="math inline">\(p\)</span></span>, the chance of success.
</p>
<p>
<span class="math display"><span class="math display">\[p = \frac{e^{b_0 +b_1x}}{1 + e^{b_0 +b_1x}}\]</span></span>
</p>
<p>
Let’s define one more term. The <strong>odds</strong> of success is the ratio of the probability of success to the probability of failure, <span class="math inline"><span class="math inline">\(p/(1-p)\)</span></span>.
</p>
<p>
With a bit more algebra and rearranging terms, we can write the above model in terms of a regression model,
</p>
<p>
<span class="math display"><span class="math display">\[\log\left(\frac{p}{1-p}\right) = b_0 +b_1x\]</span></span> On the left hand side, we have the natural log of the odds, called the <strong>logit</strong> function. On the right hand side, we have an equation for a line. This is a <strong>simple logistic regression model</strong>.
</p>
</div>
<p>Just like a linear regression model, we can extend this model to a <strong>multiple logistic regression model</strong> by adding additional x variables,</p>
<p><span class="math display">\[\log\left(\frac{p}{1-p}\right) = b_0 +b_1x_1+b_2x_2+b_3x_3+\cdots +b_kx_k\]</span></p>
</div>
<div id="fitting-the-model" class="section level3">
<h3><span class="header-section-number">3.10.2</span> Fitting the Model</h3>
<p>Based on observed data that includes responses (1 for success, 0 for failure) and predictor variables, we need to find the slope coefficients, <span class="math inline">\(b_0\)</span>,…,<span class="math inline">\(b_k\)</span> that best fits the data. The way we do this is through a technique called <strong>maximum likelihood estimation</strong>. We will not discuss the details in this class; we’ll save this for an upper level stats class.</p>
<p>In R, we do this with a general linear model function, <code>glm()</code>.</p>
<p>For a data set, let’s go back in history to January 28, 1986. On this day, the Challenger U.S. space shuttle took off and exploded about minute after the launch. After the fact, scientists ruled that the disaster was due to o-ring seal failure. Let’s look at experimental data on the o-rings prior to the fateful day.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" data-line-number="1"><span class="kw">require</span>(vcd)</a>
<a class="sourceLine" id="cb183-2" data-line-number="2"><span class="kw">data</span>(SpaceShuttle)</a>
<a class="sourceLine" id="cb183-3" data-line-number="3"></a>
<a class="sourceLine" id="cb183-4" data-line-number="4">SpaceShuttle <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb183-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(Fail)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb183-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(Fail), <span class="dt">y =</span> Temperature) )<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb183-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="Stat155Notes_files/figure-html/unnamed-chunk-180-1.png" width="672" /></p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1">SpaceShuttle <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb184-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(Fail)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb184-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(Temperature) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb184-4" data-line-number="4"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">PercentFail =</span> <span class="kw">mean</span>(Fail <span class="op">==</span><span class="st"> &#39;yes&#39;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb184-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Temperature, <span class="dt">y =</span> PercentFail)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb184-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb184-7" data-line-number="7"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="Stat155Notes_files/figure-html/unnamed-chunk-180-2.png" width="672" /></p>
<div class="reflect">
<p>
What is the plot above telling us about the relationship between chance of o-ring failure and temperature?
</p>
</div>
<p>Let’s fit a simple logistic regression model to predict the chance of o-ring failure based on the temperature using the experimental data.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" data-line-number="1">model.glm &lt;-<span class="st"> </span><span class="kw">glm</span>(Fail <span class="op">~</span><span class="st"> </span>Temperature, <span class="dt">data =</span> SpaceShuttle, <span class="dt">family =</span> binomial)</a>
<a class="sourceLine" id="cb185-2" data-line-number="2"><span class="kw">summary</span>(model.glm)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Fail ~ Temperature, family = binomial, data = SpaceShuttle)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0611  -0.7613  -0.3783   0.4524   2.2175  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  15.0429     7.3786   2.039   0.0415 *
## Temperature  -0.2322     0.1082  -2.145   0.0320 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 28.267  on 22  degrees of freedom
## Residual deviance: 20.315  on 21  degrees of freedom
##   (1 observation deleted due to missingness)
## AIC: 24.315
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">3.10.3</span> Interpretation</h3>
<p>Let’s take a look at these estimates from the model. What do they mean?</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" data-line-number="1"><span class="kw">tidy</span>(model.glm)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)   15.0       7.38       2.04  0.0415
## 2 Temperature   -0.232     0.108     -2.14  0.0320</code></pre>
<p>If you want to get a sense of what the number -0.232 means, we need to do a bit of algebra.</p>
<div class="math">
<p>
Our estimated model is
</p>
<p>
<span class="math display"><span class="math display">\[\log\left(\frac{\hat{p}}{1-\hat{p}}\right) = b_0 +b_1x\]</span></span> where <span class="math inline"><span class="math inline">\(b_0 = 15\)</span></span> and <span class="math inline"><span class="math inline">\(b_1 = -0.232\)</span></span>.
</p>
<p>
If we imagine increasing x by 1, then we get a different set of predicted probabilities of success, <span class="math inline"><span class="math inline">\(\hat{p}^*\)</span></span>,
</p>
<p>
<span class="math display"><span class="math display">\[\log\left(\frac{\hat{p}^*}{1-\hat{p}^*}\right) = b_0 +b_1(x+1)\]</span></span>
</p>
<p>
Let’s find the difference between these two equations,
</p>
<p>
<span class="math display"><span class="math display">\[\log\left(\frac{\hat{p}^*}{1-\hat{p}^*}\right) - \log\left(\frac{\hat{p}}{1-\hat{p}}\right) = b_0 +b_1(x+1) - (b_0 +b_1x)\]</span></span> and simplify the right hand side,
</p>
<p>
<span class="math display"><span class="math display">\[\log\left(\frac{\hat{p}^*}{1-\hat{p}^*}\right) - \log\left(\frac{\hat{p}}{1-\hat{p}}\right) = b_1\]</span></span> and then simplify the left hand side,
</p>
<p>
<span class="math display"><span class="math display">\[\log\left( \frac{\hat{p}^*/(1-\hat{p}^*)}{\hat{p}/(1-\hat{p})}\right) = b_1\]</span></span>
</p>
<p>
Let’s exponentiate both sides,
</p>
<p>
<span class="math display"><span class="math display">\[\left( \frac{\hat{p}^*/(1-\hat{p}^*)}{\hat{p}/(1-\hat{p})}\right) = e^{b_1}\]</span></span>
</p>
</div>
<p>We find that <span class="math inline">\(e^{b_1} = e^{-0.232} = 0.793\)</span> is the <strong>odds ratio</strong> based on increasing x by 1 unit (it is a ratio of odds).</p>
<p>If a ratio is greater than 1, that means that the denominator is less than the numerator or numerator is greater than denominator. If a ratio is less than 1, that means that the denominator is greater than the numerator or numerator is less than denominator. If the ratio is equal to one, the numerator equals the denominator (odds are equal).</p>
<p>In this case, we have a ratio &lt; 1 which means that the estimated odds of o-ring failure is lower for increased temperatures (in particular by increasing by 1 degree). This makes sense since we saw that the chance of o-ring failure decrease with warmer temperatures.</p>
</div>
<div id="prediction-1" class="section level3">
<h3><span class="header-section-number">3.10.4</span> Prediction</h3>
<p>On January 28, 1986, the temperature was 26 F degrees. Let’s predict the chance of “success,” which is a failure of o-rings in our data context, at that temperature.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" data-line-number="1"><span class="kw">predict</span>(model.glm, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Temperature =</span> <span class="dv">26</span>), <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</a></code></pre></div>
<pre><code>##         1 
## 0.9998774</code></pre>
<p>They didn’t have any experimental data testing o-rings at this low of temperatures, but even based on the data collected, they predict the chance of failure to be nearly 100% (near certainty).</p>
<div id="hard-predictionsclassifications" class="section level4">
<h4><span class="header-section-number">3.10.4.1</span> Hard Predictions/Classifications</h4>
<p>These predicted chances of “success” are useful to give us a sense of uncertainty in our prediction, but how high should the predicted chance be to do “hard” predictions of “success”?</p>
<p>It depends.</p>
<p>If we used a threshold of 0.8, then we’d say that for any experiment with a predicted chance of o-ring failure 0.8 or greater, we’ll predict that there will be o-ring failure. As with any predictions, we may make an error. With this threshold, what is our <strong>accuracy</strong> (# of correctly predicted/# of data points)?</p>
<p>In the table below, we see that there were three data points in which we correctly predicted o-ring failure. There were 4 data points in which we erroneously predicted that it wouldn’t fail when it actually did and correctly predicted no failure for 16 data points. So in total, our accuracy is (16+3)/(16+4+3) = 0.82.</p>
<p>The only errors we made were <strong>false negatives</strong>; we didn’t predict failure but failure did actual happen in the experiment. In this data context, false negatives have real consequences on human lives because a shuttle would launch and potentially explode because we had predicted there would be no o-ring failure.</p>
<p>The <strong>false negative rate</strong> is the number of false negatives divided by the false negatives + true positives (denominator should be total number of experiments with o-ring failures). With a threshold of 0.80, our false negative rate is 4/(3+4) = 0.57.</p>
<p>A <strong>false positive</strong> (predicting failure when it doesn’t happen) would delay launch but have minimal impact on human lives.</p>
<p>The <strong>false positive rate</strong> is the number of false positives divided by the false positives + true negatives (denominator should be total number of experiments with no o-ring failures). With a threshold of 0.80, our false positive rate is 0/16 = 0.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb191-1" data-line-number="1"><span class="kw">augment</span>(model.glm, <span class="dt">type.predict =</span><span class="st">&#39;response&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb191-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predictOFail =</span> .fitted <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.8</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb191-3" data-line-number="3"><span class="st">  </span><span class="kw">count</span>(Fail,predictOFail)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   Fail  predictOFail     n
##   &lt;fct&gt; &lt;lgl&gt;        &lt;int&gt;
## 1 no    FALSE           16
## 2 yes   FALSE            4
## 3 yes   TRUE             3</code></pre>
<p>What if we used a lower threshold to reduce the number of false negatives? Let’s lower it to 0.25 so that we predict o-ring failure more easily. Let’s find our accuracy: (10+4)/(10+3+6+4) = 0.61. Worse than before, but let’s check false negative rate: 3/(3+4) = 0.43. That’s lower. But now we have a fairly high false positive rate: 6/(6+10) = 0.375. So of the experiments with o-ring failure, we predicted wrong 37.5% of the time.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" data-line-number="1"><span class="kw">augment</span>(model.glm, <span class="dt">type.predict =</span><span class="st">&#39;response&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb193-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predictOFail =</span> .fitted <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.25</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb193-3" data-line-number="3"><span class="st">  </span><span class="kw">count</span>( Fail, predictOFail)</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   Fail  predictOFail     n
##   &lt;fct&gt; &lt;lgl&gt;        &lt;int&gt;
## 1 no    FALSE           10
## 2 no    TRUE             6
## 3 yes   FALSE            3
## 4 yes   TRUE             4</code></pre>
</div>
</div>
<div id="model-evaluation" class="section level3">
<h3><span class="header-section-number">3.10.5</span> Model Evaluation</h3>
<p>In deciding whether a logistic regression model is a good and useful model, we need to consider the accuracy, the false positive rate and the false negative rate. Depending on the context, we may focus on maximizing the overall accuracy or we may focus on minimizing the false negative rate or minimizing the false positive rate.</p>
</div>
<div id="alternative-classification-models" class="section level3">
<h3><span class="header-section-number">3.10.6</span> Alternative Classification Models</h3>
<p>Logistic regression is a very useful model to predict a binary outcome that is an extension of linear regression. However, it has its limitations. We are assuming a linear relationship between explanatory variables and the log odds. This is hard to check because we don’t have a variable for odds that we could then quickly plot.</p>
<p>Other methods out there are more flexible but also more complex. Sometimes for a task, complex is not necessary: see <a href="https://www.huffingtonpost.com/2014/02/10/klemens-torggler-evolution-door_n_4762261.html" class="uri">https://www.huffingtonpost.com/2014/02/10/klemens-torggler-evolution-door_n_4762261.html</a>.</p>
<ul>
<li><p>Classification Trees can predict a binary outcome and choose the variables that are most important by recursively partitioning the data into groups that are more similar in terms of the outcome as well as in chosen predictor variables.</p></li>
<li><p>Random Forests are a collection of classification tress that are more stable than one classification tree.</p></li>
<li><p>Boosted Trees are classification trees that are sequentially created to target the errors from the last tree.</p></li>
<li><p>Neural Networks are a type of classification algorithm that creates new features based on the original data that are the best predictors of the outcome.</p></li>
</ul>
<p>Take Machine Learning to learn more about these methods.</p>
<p>##Major Takeaways</p>
<ol style="list-style-type: decimal">
<li><p>All models are wrong, but some are useful and fair.</p></li>
<li><p>We want a model with small residuals (prediction errors).</p></li>
<li><p>To determine if a model is useful and fair, we study what is left over (the residuals).</p></li>
<li><p>We use models to describe phenomena by interpreting slope estimates. Make sure you are talking about the average or predicted outcome! If you have multiple variables, you keep all others fixed (if possible).</p></li>
<li><p>We also use models to prediction values, but be careful about predicting outside the observed range of our explanatory (X) variables. That is called extrapolation.</p></li>
</ol>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="multiple-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-variability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Stat155Notes.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
