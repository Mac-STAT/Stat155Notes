<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.9 Multiple Linear Regression | STAT 155 Notes</title>
  <meta name="description" content="This includes notes for Introduction to Statistical Modeling (STAT 155) at Macalester College." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3.9 Multiple Linear Regression | STAT 155 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This includes notes for Introduction to Statistical Modeling (STAT 155) at Macalester College." />
  <meta name="github-repo" content="bcheggeseth/Stat155Notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.9 Multiple Linear Regression | STAT 155 Notes" />
  
  <meta name="twitter:description" content="This includes notes for Introduction to Statistical Modeling (STAT 155) at Macalester College." />
  

<meta name="author" content="Macalester Statistics Faculty (Heggeseth, Myint, Grinde)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="conditions-for-linear-regression-models.html"/>
<link rel="next" href="selecting-a-model.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href = "./">STAT 155 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="data-collection-and-quality.html"><a href="data-collection-and-quality.html"><i class="fa fa-check"></i><b>1</b> Data Collection and Quality</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-data.html"><a href="what-is-data.html"><i class="fa fa-check"></i><b>1.1</b> What is Data?</a></li>
<li class="chapter" data-level="1.2" data-path="data-context.html"><a href="data-context.html"><i class="fa fa-check"></i><b>1.2</b> Data Context</a></li>
<li class="chapter" data-level="1.3" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>1.3</b> Sampling</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sampling.html"><a href="sampling.html#sampling-bias"><i class="fa fa-check"></i><b>1.3.1</b> Sampling Bias</a></li>
<li class="chapter" data-level="1.3.2" data-path="sampling.html"><a href="sampling.html#random-sampling"><i class="fa fa-check"></i><b>1.3.2</b> Random Sampling</a></li>
<li class="chapter" data-level="1.3.3" data-path="sampling.html"><a href="sampling.html#nonresponse-bias"><i class="fa fa-check"></i><b>1.3.3</b> Nonresponse bias</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="information-bias.html"><a href="information-bias.html"><i class="fa fa-check"></i><b>1.4</b> Information bias</a></li>
<li class="chapter" data-level="1.5" data-path="study-design.html"><a href="study-design.html"><i class="fa fa-check"></i><b>1.5</b> Study Design</a></li>
<li class="chapter" data-level="1.6" data-path="cause-and-effect.html"><a href="cause-and-effect.html"><i class="fa fa-check"></i><b>1.6</b> Cause and Effect</a></li>
<li class="chapter" data-level="1.7" data-path="ethical-considerations.html"><a href="ethical-considerations.html"><i class="fa fa-check"></i><b>1.7</b> Ethical Considerations</a></li>
<li class="chapter" data-level="1.8" data-path="chapter-1-major-takeaways.html"><a href="chapter-1-major-takeaways.html"><i class="fa fa-check"></i><b>1.8</b> Chapter 1 Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="visualizing-data.html"><a href="visualizing-data.html"><i class="fa fa-check"></i><b>2</b> Visualizing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="good-visualization-principles.html"><a href="good-visualization-principles.html"><i class="fa fa-check"></i><b>2.1</b> Good Visualization Principles</a></li>
<li class="chapter" data-level="2.2" data-path="brief-intro-to-r.html"><a href="brief-intro-to-r.html"><i class="fa fa-check"></i><b>2.2</b> Brief Intro to R</a><ul>
<li class="chapter" data-level="2.2.1" data-path="brief-intro-to-r.html"><a href="brief-intro-to-r.html#basic-syntax"><i class="fa fa-check"></i><b>2.2.1</b> Basic Syntax</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="anatomy-of-a-ggplot-command.html"><a href="anatomy-of-a-ggplot-command.html"><i class="fa fa-check"></i><b>2.3</b> Anatomy of a ggplot command</a></li>
<li class="chapter" data-level="2.4" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html"><i class="fa fa-check"></i><b>2.4</b> One Categorical Variable</a><ul>
<li class="chapter" data-level="2.4.1" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html#bar-plot"><i class="fa fa-check"></i><b>2.4.1</b> Bar Plot</a></li>
<li class="chapter" data-level="2.4.2" data-path="one-categorical-variable.html"><a href="one-categorical-variable.html#pie-chart"><i class="fa fa-check"></i><b>2.4.2</b> Pie Chart</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html"><i class="fa fa-check"></i><b>2.5</b> Two Categorical Variables</a><ul>
<li class="chapter" data-level="2.5.1" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#side-by-side-bar-plot"><i class="fa fa-check"></i><b>2.5.1</b> Side by Side Bar Plot</a></li>
<li class="chapter" data-level="2.5.2" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#stacked-bar-plot"><i class="fa fa-check"></i><b>2.5.2</b> Stacked Bar Plot</a></li>
<li class="chapter" data-level="2.5.3" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#stacked-bar-plot-relative-frequencies"><i class="fa fa-check"></i><b>2.5.3</b> Stacked Bar Plot (Relative Frequencies)</a></li>
<li class="chapter" data-level="2.5.4" data-path="two-categorical-variables.html"><a href="two-categorical-variables.html#mosaic-plot"><i class="fa fa-check"></i><b>2.5.4</b> Mosaic Plot</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html"><i class="fa fa-check"></i><b>2.6</b> One Quantitative Variable</a><ul>
<li class="chapter" data-level="2.6.1" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#histogram"><i class="fa fa-check"></i><b>2.6.1</b> Histogram</a></li>
<li class="chapter" data-level="2.6.2" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#center"><i class="fa fa-check"></i><b>2.6.2</b> Center</a></li>
<li class="chapter" data-level="2.6.3" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#boxplot"><i class="fa fa-check"></i><b>2.6.3</b> Boxplot</a></li>
<li class="chapter" data-level="2.6.4" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#spread"><i class="fa fa-check"></i><b>2.6.4</b> Spread</a></li>
<li class="chapter" data-level="2.6.5" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#intro-zscore"><i class="fa fa-check"></i><b>2.6.5</b> Some data accounting</a></li>
<li class="chapter" data-level="2.6.6" data-path="one-quantitative-variable.html"><a href="one-quantitative-variable.html#z-scores"><i class="fa fa-check"></i><b>2.6.6</b> Z-scores</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="one-quant-and-one-cat-variable.html"><a href="one-quant-and-one-cat-variable.html"><i class="fa fa-check"></i><b>2.7</b> One Quant. and One Cat. Variable</a><ul>
<li class="chapter" data-level="2.7.1" data-path="one-quant-and-one-cat-variable.html"><a href="one-quant-and-one-cat-variable.html#multiple-histograms"><i class="fa fa-check"></i><b>2.7.1</b> Multiple Histograms</a></li>
<li class="chapter" data-level="2.7.2" data-path="one-quant-and-one-cat-variable.html"><a href="one-quant-and-one-cat-variable.html#multiple-boxplots"><i class="fa fa-check"></i><b>2.7.2</b> Multiple Boxplots</a></li>
<li class="chapter" data-level="2.7.3" data-path="one-quant-and-one-cat-variable.html"><a href="one-quant-and-one-cat-variable.html#is-this-a-real-difference"><i class="fa fa-check"></i><b>2.7.3</b> Is this a Real Difference?</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html"><i class="fa fa-check"></i><b>2.8</b> Two Quantitative Variables</a><ul>
<li class="chapter" data-level="2.8.1" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#scatterplot"><i class="fa fa-check"></i><b>2.8.1</b> Scatterplot</a></li>
<li class="chapter" data-level="2.8.2" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#correlation-coefficient"><i class="fa fa-check"></i><b>2.8.2</b> Correlation Coefficient</a></li>
<li class="chapter" data-level="2.8.3" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#properties"><i class="fa fa-check"></i><b>2.8.3</b> Properties</a></li>
<li class="chapter" data-level="2.8.4" data-path="two-quantitative-variables.html"><a href="two-quantitative-variables.html#is-correlation-always-the-right-way-to-judge-strength"><i class="fa fa-check"></i><b>2.8.4</b> Is correlation always the right way to judge strength?</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html"><i class="fa fa-check"></i><b>2.9</b> Three or more variables</a><ul>
<li class="chapter" data-level="2.9.1" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#a-bivariate-scatterplot"><i class="fa fa-check"></i><b>2.9.1</b> A bivariate scatterplot</a></li>
<li class="chapter" data-level="2.9.2" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-color"><i class="fa fa-check"></i><b>2.9.2</b> Enriching with color</a></li>
<li class="chapter" data-level="2.9.3" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-shape"><i class="fa fa-check"></i><b>2.9.3</b> Enriching with shape</a></li>
<li class="chapter" data-level="2.9.4" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-size"><i class="fa fa-check"></i><b>2.9.4</b> Enriching with size</a></li>
<li class="chapter" data-level="2.9.5" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-panels"><i class="fa fa-check"></i><b>2.9.5</b> Enriching with panels</a></li>
<li class="chapter" data-level="2.9.6" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#enriching-with-smoothing"><i class="fa fa-check"></i><b>2.9.6</b> Enriching with smoothing</a></li>
<li class="chapter" data-level="2.9.7" data-path="three-or-more-variables.html"><a href="three-or-more-variables.html#putting-everything-together"><i class="fa fa-check"></i><b>2.9.7</b> Putting everything together</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="chapter-2-major-takeaways.html"><a href="chapter-2-major-takeaways.html"><i class="fa fa-check"></i><b>2.10</b> Chapter 2 Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression-models.html"><a href="linear-regression-models.html"><i class="fa fa-check"></i><b>3</b> Linear Regression Models</a><ul>
<li class="chapter" data-level="3.1" data-path="modeling-goals.html"><a href="modeling-goals.html"><i class="fa fa-check"></i><b>3.1</b> Modeling Goals</a></li>
<li class="chapter" data-level="3.2" data-path="lines.html"><a href="lines.html"><i class="fa fa-check"></i><b>3.2</b> Lines</a></li>
<li class="chapter" data-level="3.3" data-path="best-fitting-line.html"><a href="best-fitting-line.html"><i class="fa fa-check"></i><b>3.3</b> “Best” fitting line</a><ul>
<li class="chapter" data-level="3.3.1" data-path="best-fitting-line.html"><a href="best-fitting-line.html#first-idea"><i class="fa fa-check"></i><b>3.3.1</b> First idea</a></li>
<li class="chapter" data-level="3.3.2" data-path="best-fitting-line.html"><a href="best-fitting-line.html#second-idea"><i class="fa fa-check"></i><b>3.3.2</b> Second idea</a></li>
<li class="chapter" data-level="3.3.3" data-path="best-fitting-line.html"><a href="best-fitting-line.html#third-idea"><i class="fa fa-check"></i><b>3.3.3</b> Third idea</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="least-squares.html"><a href="least-squares.html"><i class="fa fa-check"></i><b>3.4</b> Least Squares</a></li>
<li class="chapter" data-level="3.5" data-path="properties-of-least-squares-line.html"><a href="properties-of-least-squares-line.html"><i class="fa fa-check"></i><b>3.5</b> Properties of Least Squares Line</a><ul>
<li class="chapter" data-level="3.5.1" data-path="properties-of-least-squares-line.html"><a href="properties-of-least-squares-line.html#real-companies"><i class="fa fa-check"></i><b>3.5.1</b> Real companies</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="model-interpretation.html"><a href="model-interpretation.html"><i class="fa fa-check"></i><b>3.6</b> Model Interpretation</a><ul>
<li class="chapter" data-level="3.6.1" data-path="model-interpretation.html"><a href="model-interpretation.html#intercept-hatbeta_0"><i class="fa fa-check"></i><b>3.6.1</b> Intercept (<span class="math inline">\(\hat{\beta}_0\)</span>)</a></li>
<li class="chapter" data-level="3.6.2" data-path="model-interpretation.html"><a href="model-interpretation.html#slope-hatbeta_1"><i class="fa fa-check"></i><b>3.6.2</b> Slope (<span class="math inline">\(\hat{\beta}_1\)</span>)</a></li>
<li class="chapter" data-level="3.6.3" data-path="model-interpretation.html"><a href="model-interpretation.html#least-squares-regression-line-haty-hatbeta_0-hatbeta_1x"><i class="fa fa-check"></i><b>3.6.3</b> Least Squares Regression Line (<span class="math inline">\(\hat{y} = \hat{\beta}_0 + \hat{\beta}_1x\)</span>)</a></li>
<li class="chapter" data-level="3.6.4" data-path="model-interpretation.html"><a href="model-interpretation.html#correlation-vs.-causation"><i class="fa fa-check"></i><b>3.6.4</b> Correlation vs. Causation</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="model-evaluation.html"><a href="model-evaluation.html"><i class="fa fa-check"></i><b>3.7</b> Model Evaluation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="model-evaluation.html"><a href="model-evaluation.html#prediction"><i class="fa fa-check"></i><b>3.7.1</b> Prediction</a></li>
<li class="chapter" data-level="3.7.2" data-path="model-evaluation.html"><a href="model-evaluation.html#prediction-errors"><i class="fa fa-check"></i><b>3.7.2</b> Prediction Errors</a></li>
<li class="chapter" data-level="3.7.3" data-path="model-evaluation.html"><a href="model-evaluation.html#r2"><i class="fa fa-check"></i><b>3.7.3</b> <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="conditions-for-linear-regression-models.html"><a href="conditions-for-linear-regression-models.html"><i class="fa fa-check"></i><b>3.8</b> Conditions for Linear Regression Models</a><ul>
<li class="chapter" data-level="3.8.1" data-path="conditions-for-linear-regression-models.html"><a href="conditions-for-linear-regression-models.html#residual-plot"><i class="fa fa-check"></i><b>3.8.1</b> Residual Plot</a></li>
<li class="chapter" data-level="3.8.2" data-path="conditions-for-linear-regression-models.html"><a href="conditions-for-linear-regression-models.html#sensitivity-analysis"><i class="fa fa-check"></i><b>3.8.2</b> Sensitivity Analysis</a></li>
<li class="chapter" data-level="3.8.3" data-path="conditions-for-linear-regression-models.html"><a href="conditions-for-linear-regression-models.html#issues-and-solutions"><i class="fa fa-check"></i><b>3.8.3</b> Issues and Solutions</a></li>
<li class="chapter" data-level="3.8.4" data-path="conditions-for-linear-regression-models.html"><a href="conditions-for-linear-regression-models.html#solutions-for-curvature"><i class="fa fa-check"></i><b>3.8.4</b> Solutions for Curvature</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="multiple.html"><a href="multiple.html"><i class="fa fa-check"></i><b>3.9</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.9.1" data-path="multiple.html"><a href="multiple.html#indicator-variables"><i class="fa fa-check"></i><b>3.9.1</b> Indicator Variables</a></li>
<li class="chapter" data-level="3.9.2" data-path="multiple.html"><a href="multiple.html#confounder-adjustment"><i class="fa fa-check"></i><b>3.9.2</b> Confounder Adjustment</a></li>
<li class="chapter" data-level="3.9.3" data-path="multiple.html"><a href="multiple.html#interaction-variables"><i class="fa fa-check"></i><b>3.9.3</b> Interaction Variables</a></li>
<li class="chapter" data-level="3.9.4" data-path="multiple.html"><a href="multiple.html#is-the-difference-real"><i class="fa fa-check"></i><b>3.9.4</b> Is the Difference Real?</a></li>
<li class="chapter" data-level="3.9.5" data-path="multiple.html"><a href="multiple.html#redundant"><i class="fa fa-check"></i><b>3.9.5</b> Redundancy and Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="selecting-a-model.html"><a href="selecting-a-model.html"><i class="fa fa-check"></i><b>3.10</b> Selecting a Model</a><ul>
<li class="chapter" data-level="3.10.1" data-path="selecting-a-model.html"><a href="selecting-a-model.html#satisfying-conditions"><i class="fa fa-check"></i><b>3.10.1</b> Satisfying conditions</a></li>
<li class="chapter" data-level="3.10.2" data-path="selecting-a-model.html"><a href="selecting-a-model.html#provide-useful-model"><i class="fa fa-check"></i><b>3.10.2</b> Provide useful model</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="dag.html"><a href="dag.html"><i class="fa fa-check"></i><b>3.11</b> Causal Inference</a></li>
<li class="chapter" data-level="3.12" data-path="chapter-3-major-takeaways.html"><a href="chapter-3-major-takeaways.html"><i class="fa fa-check"></i><b>3.12</b> Chapter 3 Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic-regression-models.html"><a href="logistic-regression-models.html"><i class="fa fa-check"></i><b>4</b> Logistic Regression Models</a><ul>
<li class="chapter" data-level="4.1" data-path="logistic-and-logit.html"><a href="logistic-and-logit.html"><i class="fa fa-check"></i><b>4.1</b> Logistic and Logit</a></li>
<li class="chapter" data-level="4.2" data-path="fitting-the-model.html"><a href="fitting-the-model.html"><i class="fa fa-check"></i><b>4.2</b> Fitting the Model</a></li>
<li class="chapter" data-level="4.3" data-path="coefficient-interpretation.html"><a href="coefficient-interpretation.html"><i class="fa fa-check"></i><b>4.3</b> Coefficient Interpretation</a></li>
<li class="chapter" data-level="4.4" data-path="model-evaluation.html"><a href="model-evaluation.html#prediction"><i class="fa fa-check"></i><b>4.4</b> Prediction</a><ul>
<li class="chapter" data-level="4.4.1" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>4.4.1</b> Hard Predictions/Classifications</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="logistic-model-evaluation.html"><a href="logistic-model-evaluation.html"><i class="fa fa-check"></i><b>4.5</b> Logistic Model Evaluation</a></li>
<li class="chapter" data-level="4.6" data-path="alternative-classification-models.html"><a href="alternative-classification-models.html"><i class="fa fa-check"></i><b>4.6</b> Alternative Classification Models</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="random-variability.html"><a href="random-variability.html"><i class="fa fa-check"></i><b>5</b> Random Variability</a><ul>
<li class="chapter" data-level="5.1" data-path="sampling-variability.html"><a href="sampling-variability.html"><i class="fa fa-check"></i><b>5.1</b> Sampling Variability</a></li>
<li class="chapter" data-level="5.2" data-path="randomization-variability.html"><a href="randomization-variability.html"><i class="fa fa-check"></i><b>5.2</b> Randomization Variability</a></li>
<li class="chapter" data-level="5.3" data-path="simulating-random-sampling-from-a-population.html"><a href="simulating-random-sampling-from-a-population.html"><i class="fa fa-check"></i><b>5.3</b> Simulating Random Sampling from a Population</a></li>
<li class="chapter" data-level="5.4" data-path="irl-bootstrapping.html"><a href="irl-bootstrapping.html"><i class="fa fa-check"></i><b>5.4</b> IRL: Bootstrapping</a></li>
<li class="chapter" data-level="5.5" data-path="simulating-randomization-into-groups.html"><a href="simulating-randomization-into-groups.html"><i class="fa fa-check"></i><b>5.5</b> Simulating Randomization into Groups</a></li>
<li class="chapter" data-level="5.6" data-path="irl-randomization-tests.html"><a href="irl-randomization-tests.html"><i class="fa fa-check"></i><b>5.6</b> IRL: Randomization Tests</a></li>
<li class="chapter" data-level="5.7" data-path="chapter-5-major-takeaways.html"><a href="chapter-5-major-takeaways.html"><i class="fa fa-check"></i><b>5.7</b> Chapter 5 Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="randomness-and-probability.html"><a href="randomness-and-probability.html"><i class="fa fa-check"></i><b>6</b> Randomness and Probability</a><ul>
<li class="chapter" data-level="6.1" data-path="three-types-of-probability.html"><a href="three-types-of-probability.html"><i class="fa fa-check"></i><b>6.1</b> Three Types of Probability</a></li>
<li class="chapter" data-level="6.2" data-path="theoretical-probability-rules.html"><a href="theoretical-probability-rules.html"><i class="fa fa-check"></i><b>6.2</b> Theoretical Probability Rules</a><ul>
<li class="chapter" data-level="6.2.1" data-path="theoretical-probability-rules.html"><a href="theoretical-probability-rules.html#diagnotic-testing-and-probability"><i class="fa fa-check"></i><b>6.2.1</b> Diagnotic Testing and Probability</a></li>
<li class="chapter" data-level="6.2.2" data-path="theoretical-probability-rules.html"><a href="theoretical-probability-rules.html#court-arguments-and-probability"><i class="fa fa-check"></i><b>6.2.2</b> Court Arguments and Probability</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="random-variable.html"><a href="random-variable.html"><i class="fa fa-check"></i><b>6.3</b> Random Variable</a></li>
<li class="chapter" data-level="6.4" data-path="probability-models.html"><a href="probability-models.html"><i class="fa fa-check"></i><b>6.4</b> Probability Models</a><ul>
<li class="chapter" data-level="6.4.1" data-path="probability-models.html"><a href="probability-models.html#using-probability-mass-functions"><i class="fa fa-check"></i><b>6.4.1</b> Using probability mass functions</a></li>
<li class="chapter" data-level="6.4.2" data-path="probability-models.html"><a href="probability-models.html#using-probability-density-functions"><i class="fa fa-check"></i><b>6.4.2</b> Using probability density functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="probability-models.html"><a href="probability-models.html#expected-value-and-variance"><i class="fa fa-check"></i><b>6.4.3</b> Expected value and variance</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="bernoullibinomial-model.html"><a href="bernoullibinomial-model.html"><i class="fa fa-check"></i><b>6.5</b> Bernoulli/Binomial Model</a></li>
<li class="chapter" data-level="6.6" data-path="normal-model.html"><a href="normal-model.html"><i class="fa fa-check"></i><b>6.6</b> Normal Model</a></li>
<li class="chapter" data-level="6.7" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html"><i class="fa fa-check"></i><b>6.7</b> Sampling Distribution and CLT</a><ul>
<li class="chapter" data-level="6.7.1" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html#sampling-distributions"><i class="fa fa-check"></i><b>6.7.1</b> Sampling distributions</a></li>
<li class="chapter" data-level="6.7.2" data-path="sampling-distribution-and-clt.html"><a href="sampling-distribution-and-clt.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>6.7.2</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html"><i class="fa fa-check"></i><b>6.8</b> Z-scores and the Student’s “t” distribution</a><ul>
<li class="chapter" data-level="6.8.1" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#gossets-work"><i class="fa fa-check"></i><b>6.8.1</b> Gosset’s Work</a></li>
<li class="chapter" data-level="6.8.2" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#beer-helps-the-field-of-statistics"><i class="fa fa-check"></i><b>6.8.2</b> Beer Helps the Field of Statistics</a></li>
<li class="chapter" data-level="6.8.3" data-path="z-scores-and-the-students-t-distribution.html"><a href="z-scores-and-the-students-t-distribution.html#students-t-model"><i class="fa fa-check"></i><b>6.8.3</b> Student’s T Model</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="chapter-6-major-takeaways.html"><a href="chapter-6-major-takeaways.html"><i class="fa fa-check"></i><b>6.9</b> Chapter 6 Major Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>7</b> Statistical Inference</a><ul>
<li class="chapter" data-level="7.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>7.1</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="7.1.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#via-classical-theory"><i class="fa fa-check"></i><b>7.1.1</b> Via Classical Theory</a></li>
<li class="chapter" data-level="7.1.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#via-bootstrapping"><i class="fa fa-check"></i><b>7.1.2</b> Via Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html"><i class="fa fa-check"></i><b>7.2</b> Confidence Interval Examples</a><ul>
<li class="chapter" data-level="7.2.1" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#proportion-outcome"><i class="fa fa-check"></i><b>7.2.1</b> Proportion Outcome</a></li>
<li class="chapter" data-level="7.2.2" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#mean-and-then-median"><i class="fa fa-check"></i><b>7.2.2</b> Mean and then Median</a></li>
<li class="chapter" data-level="7.2.3" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#logistic-regression-model"><i class="fa fa-check"></i><b>7.2.3</b> Logistic Regression Model</a></li>
<li class="chapter" data-level="7.2.4" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#linear-regression-model-slope-categorical-variable"><i class="fa fa-check"></i><b>7.2.4</b> Linear Regression Model Slope (Categorical Variable)</a></li>
<li class="chapter" data-level="7.2.5" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#linear-regression-model-slope-quantitative-var"><i class="fa fa-check"></i><b>7.2.5</b> Linear Regression Model Slope (Quantitative Var)</a></li>
<li class="chapter" data-level="7.2.6" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#confidence-intervals-for-prediction"><i class="fa fa-check"></i><b>7.2.6</b> Confidence Intervals for Prediction</a></li>
<li class="chapter" data-level="7.2.7" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#prediction-intervals"><i class="fa fa-check"></i><b>7.2.7</b> Prediction Intervals</a></li>
<li class="chapter" data-level="7.2.8" data-path="confidence-interval-examples.html"><a href="confidence-interval-examples.html#probability-theory-vs.-bootstrapping"><i class="fa fa-check"></i><b>7.2.8</b> Probability Theory vs. Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>7.3</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="7.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-statistics"><i class="fa fa-check"></i><b>7.3.1</b> Test statistics</a></li>
<li class="chapter" data-level="7.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#logic-of-hypothesis-testing"><i class="fa fa-check"></i><b>7.3.2</b> Logic of hypothesis testing</a></li>
<li class="chapter" data-level="7.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#summary-of-procedure"><i class="fa fa-check"></i><b>7.3.3</b> Summary of procedure</a></li>
<li class="chapter" data-level="7.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#testing-single-model-coefficients"><i class="fa fa-check"></i><b>7.3.4</b> Testing single model coefficients</a></li>
<li class="chapter" data-level="7.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#distributions-of-test-statistics"><i class="fa fa-check"></i><b>7.3.5</b> Distributions of test statistics</a></li>
<li class="chapter" data-level="7.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#graphical-description-of-p-values"><i class="fa fa-check"></i><b>7.3.6</b> Graphical description of p-values</a></li>
<li class="chapter" data-level="7.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-linear-regression"><i class="fa fa-check"></i><b>7.3.7</b> Example: Linear Regression</a></li>
<li class="chapter" data-level="7.3.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-logistic-regression"><i class="fa fa-check"></i><b>7.3.8</b> Example: Logistic Regression</a></li>
<li class="chapter" data-level="7.3.9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors"><i class="fa fa-check"></i><b>7.3.9</b> Errors</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="statistical-significance-v-practical-significance.html"><a href="statistical-significance-v-practical-significance.html"><i class="fa fa-check"></i><b>7.4</b> Statistical Significance v. Practical Significance</a></li>
<li class="chapter" data-level="7.5" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>7.5</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="appendix-a-theoretical-probability.html"><a href="appendix-a-theoretical-probability.html"><i class="fa fa-check"></i><b>8</b> Appendix A - Theoretical Probability</a><ul>
<li class="chapter" data-level="8.1" data-path="probability-rules.html"><a href="probability-rules.html"><i class="fa fa-check"></i><b>8.1</b> Probability Rules</a><ul>
<li class="chapter" data-level="8.1.1" data-path="probability-rules.html"><a href="probability-rules.html#disjointmutually-exclusive"><i class="fa fa-check"></i><b>8.1.1</b> Disjoint/Mutually Exclusive</a></li>
<li class="chapter" data-level="8.1.2" data-path="probability-rules.html"><a href="probability-rules.html#independence"><i class="fa fa-check"></i><b>8.1.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="theory-of-random-variable.html"><a href="theory-of-random-variable.html"><i class="fa fa-check"></i><b>8.2</b> Theory of Random Variable</a><ul>
<li class="chapter" data-level="8.2.1" data-path="probability-models.html"><a href="probability-models.html#probability-models"><i class="fa fa-check"></i><b>8.2.1</b> Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>8.3</b> Discrete Random Variables</a><ul>
<li class="chapter" data-level="8.3.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-value"><i class="fa fa-check"></i><b>8.3.1</b> Expected Value</a></li>
<li class="chapter" data-level="8.3.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>8.3.2</b> Variance</a></li>
<li class="chapter" data-level="8.3.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#joint-distributions"><i class="fa fa-check"></i><b>8.3.3</b> Joint Distributions</a></li>
<li class="chapter" data-level="8.3.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#covariance"><i class="fa fa-check"></i><b>8.3.4</b> Covariance</a></li>
<li class="chapter" data-level="8.3.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#correlation"><i class="fa fa-check"></i><b>8.3.5</b> Correlation</a></li>
<li class="chapter" data-level="8.3.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#a-few-named-probability-models"><i class="fa fa-check"></i><b>8.3.6</b> A Few Named Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html"><i class="fa fa-check"></i><b>8.4</b> Continuous Random Variables</a><ul>
<li class="chapter" data-level="8.4.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#expected-value-1"><i class="fa fa-check"></i><b>8.4.1</b> Expected Value</a></li>
<li class="chapter" data-level="8.4.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#a-few-named-probability-models-1"><i class="fa fa-check"></i><b>8.4.2</b> A Few Named Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="random-variation.html"><a href="random-variation.html"><i class="fa fa-check"></i><b>8.5</b> Random Variation</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>9</b> Definitions</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>9.1</b> Chapter 1</a></li>
<li class="chapter" data-level="9.2" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>9.2</b> Chapter 2</a></li>
<li class="chapter" data-level="9.3" data-path="chapter-3.html"><a href="chapter-3.html"><i class="fa fa-check"></i><b>9.3</b> Chapter 3</a></li>
<li class="chapter" data-level="9.4" data-path="chapter-4.html"><a href="chapter-4.html"><i class="fa fa-check"></i><b>9.4</b> Chapter 4</a></li>
<li class="chapter" data-level="9.5" data-path="chapter-5.html"><a href="chapter-5.html"><i class="fa fa-check"></i><b>9.5</b> Chapter 5</a></li>
<li class="chapter" data-level="9.6" data-path="chapter-6.html"><a href="chapter-6.html"><i class="fa fa-check"></i><b>9.6</b> Chapter 6</a></li>
<li class="chapter" data-level="9.7" data-path="chapter-7.html"><a href="chapter-7.html"><i class="fa fa-check"></i><b>9.7</b> Chapter 7</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 155 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple" class="section level2">
<h2><span class="header-section-number">3.9</span> Multiple Linear Regression</h2>
<p>As we’ve alluded to, we can generalize the idea of a simple linear regression model by including many predictor variables (<span class="math inline">\(X\)</span>’s). A <strong>multiple linear regression model</strong> can be written as:</p>
<p><span class="math display">\[ E[Y |X_1,...,X_k ] = \beta_0 + \beta_1\,X_{1} + \cdots + \beta_k\,X_{k}  \]</span></p>
<ul>
<li><p>Each “slope” coefficient <span class="math inline">\(\beta_j\)</span> can be interpreted as the increase in the expected or average <span class="math inline">\(Y\)</span> associated with a 1 unit increase in <span class="math inline">\(X_j\)</span>, <strong>keeping all other variables fixed or constant</strong>. (*There are some exceptions - we’ll get there.)</p></li>
<li><p>These explanatory variables can be:</p>
<ul>
<li>Quantitative variables (or transformations of them)</li>
<li><a href="multiple.html#indicator-variables">Indicator variables</a> for categorical variables (only need <span class="math inline">\(L-1\)</span> indicators for a variable with <span class="math inline">\(L\)</span> categories)</li>
<li><a href="multiple.html#interaction-variables">Interaction terms</a> (product of two variables, which allows for <em>effect modification</em>)</li>
</ul></li>
</ul>
<p>Let’s talk about a new data example: home prices. We want to build a model to predict the price of a home based on its many characteristics. We have a dataset of homes recently sold in New England with many variables such as the age of the home, the land value, whether or not it has central air conditioning, the number of fireplaces, the sale price, and more…</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="multiple.html#cb174-1"></a>homes &lt;-<span class="st"> </span><span class="kw">read.delim</span>(<span class="st">&#39;Data/Saratoga.txt&#39;</span>)</span>
<span id="cb174-2"><a href="multiple.html#cb174-2"></a><span class="kw">head</span>(homes)</span></code></pre></div>
<pre><code>##    Price Lot.Size Waterfront Age Land.Value New.Construct Central.Air Fuel.Type
## 1 132500     0.09          0  42      50000             0           0         3
## 2 181115     0.92          0   0      22300             0           0         2
## 3 109000     0.19          0 133       7300             0           0         2
## 4 155000     0.41          0  13      18700             0           0         2
## 5  86060     0.11          0   0      15000             1           1         2
## 6 120000     0.68          0  31      14000             0           0         2
##   Heat.Type Sewer.Type Living.Area Pct.College Bedrooms Fireplaces Bathrooms
## 1         4          2         906          35        2          1       1.0
## 2         3          2        1953          51        3          0       2.5
## 3         3          3        1944          51        4          1       1.0
## 4         2          2        1944          51        3          1       1.5
## 5         2          3         840          51        2          0       1.0
## 6         2          2        1152          22        4          1       1.0
##   Rooms
## 1     5
## 2     6
## 3     8
## 4     5
## 5     3
## 6     8</code></pre>
<p>*The exception to the interpretation comment above is if some of our <span class="math inline">\(X\)</span> variables are strongly correlated (called <strong>multicollinearity</strong>). In this case, we cannot hold all other variables constant (at least not well) because if we increase the value of one variable, then variables highly correlated with it will also likely change in value.</p>
<div id="indicator-variables" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Indicator Variables</h3>
<p>In New England, fireplaces are often used as a way to provide supplementary heat to the house. Let’s study the impact of a fireplace has on the sale price of a home. In particular, we only care if the home has 1 or more fireplaces or no fireplaces. So we make a new variable, <code>AnyFireplace</code>, that is <code>TRUE</code> if there is at least one fireplace in a home and <code>FALSE</code> otherwise.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="multiple.html#cb176-1"></a>homes &lt;-<span class="st"> </span>homes <span class="op">%&gt;%</span></span>
<span id="cb176-2"><a href="multiple.html#cb176-2"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">AnyFireplace =</span> Fireplaces <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</span></code></pre></div>
<p>In order to include this information in our linear regression model, we need to turn that categorical variable (<code>AnyFireplace</code> with values of <code>TRUE</code> or <code>FALSE</code>) into a quantitative variable using an <strong>indicator variable</strong>, which has a numeric value of 0 or 1:</p>
<p><span class="math display">\[ \hbox{AnyFireplaceTRUE} = \begin{cases}1 \quad \text{ if a home has at least one fireplace}\\ 0\quad \text{ if a home does not have a fireplace} \end{cases}\]</span>
Our model is written as</p>
<p><span class="math display">\[E[\hbox{Price} | \hbox{AnyFireplace}] = \beta_0 + \beta_1 \hbox{AnyFireplaceTRUE}\]</span></p>
<p><strong>What does this mean?</strong></p>
<p>Let’s think about two types of homes: a home with one or more fireplaces and a home without a fireplace. Let’s write out the model equations for those two types of homes.</p>
<ul>
<li><p>Home with fireplace (indicator variable = 1):<br />
<span class="math display">\[E[\hbox{Price} | \hbox{AnyFireplace} = TRUE] = \beta_0 + \beta_1*1 = \beta_0+\beta_1\]</span></p></li>
<li><p>Home without fireplace (indicator variable = 0):<br />
<span class="math display">\[E[\hbox{Price} | \hbox{AnyFireplace} = FALSE] = \beta_0 + \beta_1*0 = \beta_0\]</span>
The difference between the expected price is <span class="math inline">\(\beta_1\)</span>, the value of the “slope” coefficient for the indicator variable (also referred to as the <code>AnyFireplaceTRUE</code> coefficient).</p></li>
</ul>
<p>To get an estimate of <span class="math inline">\(\beta_1\)</span>, we need to fit our model to the data. In fact, R creates this indicator variable for you when you include a categorical variable as an <span class="math inline">\(X\)</span> variable the <code>lm()</code> function.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="multiple.html#cb177-1"></a>lm.home &lt;-<span class="st"> </span><span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>AnyFireplace, <span class="dt">data =</span> homes)</span>
<span id="cb177-2"><a href="multiple.html#cb177-2"></a><span class="kw">summary</span>(lm.home)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ AnyFireplace, data = homes)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -234914  -59653  -18784   42145  585347 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        174653       3419   51.08   &lt;2e-16 ***
## AnyFireplaceTRUE    65261       4522   14.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 93020 on 1726 degrees of freedom
## Multiple R-squared:  0.1077,	Adjusted R-squared:  0.1072 
## F-statistic: 208.3 on 1 and 1726 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Our best fitting “line” is</p>
<p><span class="math display">\[ \hbox{Predicted Price} = 174653 + 65261\,\hbox{AnyFireplaceTRUE} \]</span>
and our predicted price for a house with a fireplace (indicator variable = 1) is</p>
<p><span class="math display">\[ \hbox{Predicted Price} = 174653 + 65261 \times 1 = \$ 239,914 \]</span></p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="multiple.html#cb179-1"></a><span class="dv">174653</span> <span class="op">+</span><span class="st"> </span><span class="dv">65261</span><span class="op">*</span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 239914</code></pre>
<p>and the predicted price for a house without a fireplace (indicator variable = 0) is</p>
<p><span class="math display">\[\hbox{Predicted Price} = 174653 + 65261 \times 0 = \$ 174,653\]</span></p>
<p>The difference between these predicted prices is <span class="math inline">\(\hat{\beta}_1\)</span> = $65,261, the estimated value of the “slope” for the indicator variable.</p>
<div class="reflect">
<p>
So is this how much a fireplace is worth? If I installed a fireplace in my house, should the value of my house go up $65,260?
</p>
<p>
<strong>No</strong>, because we should not make causal statements based on observational data without thinking deeply about the context. What could be confounding this relationship? What third variable may be related to both the price and whether or not a house has a fireplace?
</p>
</div>
</div>
<div id="confounder-adjustment" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Confounder Adjustment</h3>
<p>Let’s consider the size of the house. Is price related to the area of living space (square footage)?</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="multiple.html#cb181-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb181-2"><a href="multiple.html#cb181-2"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Living.Area, <span class="dt">y =</span> Price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb181-3"><a href="multiple.html#cb181-3"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&#39;steelblue&#39;</span>) <span class="op">+</span></span>
<span id="cb181-4"><a href="multiple.html#cb181-4"></a><span class="st">    </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>Is the presence of a fireplace related to area of living space?</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="multiple.html#cb182-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb182-2"><a href="multiple.html#cb182-2"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> AnyFireplace, <span class="dt">y =</span> Living.Area)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb182-3"><a href="multiple.html#cb182-3"></a><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></span>
<span id="cb182-4"><a href="multiple.html#cb182-4"></a><span class="st">    </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>We see that the amount of living area differs between homes with fireplaces and homes without fireplaces. Thus, <code>Living.Area</code> could confound the relationship between <code>AnyFireplace</code> and <code>Price</code> because it is related to both variables. That is, it is possible that Living Area is a cause of having a fireplace and Living Area also clearly is a cause of Price.</p>
<p>Let’s put <code>Living.Area</code> in the model along with <code>AnyFireplace</code> to account for it (to control or adjust for it),</p>
<p><span class="math display">\[E[\hbox{Price} | \hbox{AnyFireplace, Living.Area}] = \beta_0 + \beta_1\,\hbox{AnyFireplaceTRUE} + \beta_2\,\hbox{Living.Area}\]</span></p>
<p><strong>What does this mean?</strong></p>
<p>Let’s think about two types of homes: a home with one or more fireplaces and a home without a fireplace.</p>
<ul>
<li>Home with fireplace (indicator = 1):</li>
</ul>
<p><span class="math display">\[\begin{align*}
E[\hbox{Price}| \hbox{AnyFireplace = TRUE, Living.Area}] &amp;= \beta_0 + \beta_1 \times 1 + \beta_2 \times \hbox{Living.Area} \\
&amp;= (\beta_0 + \beta_1 ) + \beta_2 \times \hbox{Living.Area}
\end{align*}\]</span></p>
<p><em>Among homes with a fireplace, we have one linear relationship between living area and price. The intercept is <span class="math inline">\(\beta_0+\beta_1\)</span> and the slope is <span class="math inline">\(\beta_2\)</span>.</em></p>
<ul>
<li>Home without fireplace (indicator = 0):</li>
</ul>
<p><span class="math display">\[\begin{align*}
E[\hbox{Price}| \hbox{AnyFireplace = FALSE, Living.Area}] &amp;= \beta_0 + \beta_1 \times 0 + \beta_2 \times \hbox{Living.Area} \\
&amp;= \beta_0 + \beta_2 \times \hbox{Living.Area}
\end{align*}\]</span></p>
<p><em>Among homes without a fireplace, we have a different linear relationship between living area and price. The intercept is <span class="math inline">\(\beta_0\)</span> and the slope is <span class="math inline">\(\beta_2\)</span>.</em></p>
<ul>
<li>For either type of home, <span class="math inline">\(\beta_2\)</span> is the increase in the expected or average Price associated with a 1 square footage increase in Living.Area, <strong>holding the number of fireplaces constant</strong>.</li>
</ul>
<p>Now let’s compare homes that are the same size.</p>
<p><em>If we keep Living.Area constant by considering two equally sized homes, then we’d expect the home with the fireplace to be worth <span class="math inline">\(\beta_1\)</span> more than a home without a fireplace.</em></p>
<p>We see this by taking the difference between the two equations, fixing the Living Area:</p>
<p><span class="math display">\[E[\hbox{Price}| \hbox{AnyFireplace = TRUE, Living.Area = A}] - E[\hbox{Price}| \hbox{AnyFireplace = FALSE, Living.Area = A}]\]</span></p>
<p><span class="math display">\[
\begin{align*}
\,&amp;= (\beta_0+\beta_1 + \beta_2 \times \hbox{A}) - ( \beta_0 + \beta_2 \times \hbox{A})\\
\,&amp;= \beta_1
\end{align*}
\]</span></p>
<p>Another way to describe <span class="math inline">\(\beta_1\)</span> is that it is the difference between the intercepts.</p>
<p>To get the estimates of <span class="math inline">\(\beta_0,\beta_1,\)</span> and <span class="math inline">\(\beta_2\)</span>, we fit the model in R,</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="multiple.html#cb183-1"></a>lm.home2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>AnyFireplace <span class="op">+</span><span class="st"> </span>Living.Area, <span class="dt">data =</span> homes)</span>
<span id="cb183-2"><a href="multiple.html#cb183-2"></a><span class="kw">summary</span>(lm.home2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ AnyFireplace + Living.Area, data = homes)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -271421  -39935   -7887   28215  554651 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      13599.164   4991.695   2.724  0.00651 ** 
## AnyFireplaceTRUE  5567.377   3716.947   1.498  0.13436    
## Living.Area        111.218      2.968  37.476  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 69080 on 1725 degrees of freedom
## Multiple R-squared:  0.5081,	Adjusted R-squared:  0.5076 
## F-statistic:   891 on 2 and 1725 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Our best fitting “line” is</p>
<p><span class="math display">\[\hbox{Predicted Price} = 13599.16 + 5567.37\,\hbox{AnyFireplaceTRUE} + 111.21\,\hbox{Living.Area}\]</span></p>
<ul>
<li><p>$111.21 is the estimated increase in the expected or average Price associated with a 1 square foot increase in Living.Area, <strong>holding all other variables (AnyFireplace) constant</strong>.</p></li>
<li><p>$5567.37 is the estimated increase in the expected or average Price associated with a 1 unit increase in AnyFireplace (going from FALSE to TRUE), <strong>holding all other variables (Living.Area) constant</strong>.</p></li>
</ul>
<p>Note that the “slope” for the indicator variable is very different with the addition of Living.Area. This suggests that <code>Living.Area</code> was confounding the relationship between <code>Price</code> and <code>AnyFireplace</code>.</p>
<p>Let’s look back at the relationship between Living.Area and Price and color the scatterplot by AnyFireplace. So we are now looking at three variables at a time. The above model with AnyFireplace and Living.Area results in two lines for Living.Area v. Price, with different intercepts but the same slope (parallel lines).</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="multiple.html#cb185-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb185-2"><a href="multiple.html#cb185-2"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Living.Area, <span class="dt">y =</span> Price, <span class="dt">color =</span> AnyFireplace)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb185-3"><a href="multiple.html#cb185-3"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb185-4"><a href="multiple.html#cb185-4"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="fl">13599.164</span> , <span class="dt">slope =</span> <span class="fl">111.218</span>, <span class="dt">color =</span> scales<span class="op">::</span><span class="kw">hue_pal</span>()(<span class="dv">2</span>)[<span class="dv">1</span>]) <span class="op">+</span></span>
<span id="cb185-5"><a href="multiple.html#cb185-5"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="fl">13599.164</span> <span class="op">+</span><span class="st"> </span><span class="fl">5567.377</span>, <span class="dt">slope =</span> <span class="fl">111.218</span> , <span class="dt">color =</span> scales<span class="op">::</span><span class="kw">hue_pal</span>()(<span class="dv">2</span>)[<span class="dv">2</span>]) <span class="op">+</span></span>
<span id="cb185-6"><a href="multiple.html#cb185-6"></a><span class="st">    </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>Let’s try and fit two separate lines to these two groups of homes, home with any fireplaces and home with no fireplaces. Do these lines have the same intercepts? Same slopes?</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="multiple.html#cb186-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb186-2"><a href="multiple.html#cb186-2"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Living.Area, <span class="dt">y =</span> Price, <span class="dt">color =</span> AnyFireplace)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb186-3"><a href="multiple.html#cb186-3"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb186-4"><a href="multiple.html#cb186-4"></a><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&#39;lm&#39;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb186-5"><a href="multiple.html#cb186-5"></a><span class="st">    </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>In this case, it look as though having a fireplace in your house slightly changes the relationship between Living.Area and Price. In fact, the increase in your average price for every 1 square foot is greater for a home with a fireplace than that for homes without fireplaces (slopes are different).</p>
</div>
<div id="interaction-variables" class="section level3">
<h3><span class="header-section-number">3.9.3</span> Interaction Variables</h3>
<p>We can allow for different slopes within one regression model (!), rather than fitting two separate models.</p>
<div class="reflect">
<p>
When should we fit only one model; when should we fit separate models?
</p>
<p>
If we fit separate models, we are <strong>stratifying</strong> and then modeling. But what if some of the strata are small?
</p>
<p>
Fitting one model allows us to “borrow information across groups.”
</p>
<p>
There is no one right answer. Researchers struggle with this decision <a href="https://www.ncbi.nlm.nih.gov/pubmed/22125224">to stratify or not to stratify</a>.
</p>
</div>
<ul>
<li><p>If we add a variable in the model (without an interaction), it only changes the intercept.</p></li>
<li><p>We can achieve different slopes by allowing a variable <span class="math inline">\(X_1\)</span> to affect the slope for another variable <span class="math inline">\(X_2\)</span>. That is, <span class="math inline">\(X_1\)</span> impacts the effect of <span class="math inline">\(X_2\)</span> on the outcome <span class="math inline">\(Y\)</span>. (Fireplace presence impacts the effect of living area on house price.)</p></li>
</ul>
<p><span class="math display">\[\beta_2 = a + bX_1\]</span>
This is called <strong>effect modification</strong> (when one variable can modify the effect of another variable on the outcome).</p>
<ul>
<li>A model with effect modification looks like this:
<span class="math display">\[E[Y | X_1, X_2] = \beta_0 + \beta_1X_{1} + \beta_2X_{2}= \beta_0 + \beta_1X_{1} + (a+bX_1)X_{2}= \beta_0 + \beta_1X_{1} +aX_2+bX_1X_{2}\]</span>
The model above has an <strong>interaction term,</strong> which is the product of two variables. Here we have <span class="math inline">\(X_1*X_2\)</span>.</li>
</ul>
<p>Let’s build a model with effect modification for our housing data. Let’s include an interaction term between AnyFireplace and Living.Area to allow for different slopes.</p>
<p><span class="math display">\[E[\hbox{Price}| \hbox{AnyFireplace, Living.Area}] = \beta_0+ \beta_1\,\hbox{AnyFireplaceTRUE} + \beta_2\,\hbox{Living.Area}+ \beta_3\,\hbox{AnyFireplaceTRUE}*\hbox{Living.Area}\]</span></p>
<p><strong>What does this mean?</strong></p>
<p>Let’s think about two types of homes: a home with one or more fireplaces and a home without a fireplace.</p>
<ul>
<li>Home with fireplace (indicator = 1):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
E[\hbox{Price}| \hbox{AnyFireplace = TRUE, Living.Area}] &amp;= \beta_0 + \beta_1*\,1 + \beta_2\,\hbox{Living.Area}+ \beta_3*\,1*\hbox{Living.Area}\\
&amp;= (\beta_0 + \beta_1) + (\beta_2+\beta_3)\,\hbox{Living.Area}\\
\end{align*}
\]</span></p>
<ul>
<li>Home without fireplace (indicator = 0):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
E[\hbox{Price}| \hbox{AnyFireplace = FALSE, Living.Area}] &amp;= \beta_0 + \beta_1*\,0 + \beta_2\,\hbox{Living.Area}+ \beta_3*\,0*\hbox{Living.Area}\\
&amp;= \beta_0  + \beta_2\,\hbox{Living.Area}\\
\end{align*}
\]</span></p>
<p>Note that there are different intercepts <strong>and</strong> different slopes for these two groups of homes. Thus, including an interaction term between a categorical and a quantitative predictor variable allows us to describe <strong>effect modification</strong>. How does the effect of one variable on the response variable differ according to another variable? How is the effect modified by another variable?</p>
<ul>
<li><span class="math inline">\(\beta_1\)</span> is the difference in the intercepts between homes with and without a fireplace</li>
<li><span class="math inline">\(\beta_3\)</span> is the difference in the slopes between homes with and without a fireplace</li>
</ul>
<p>What this means in the context of this model of price as a function of living area and fireplaces: different slopes means that the average rate of price increase for every additional square foot is <strong>different between homes with and without fireplaces</strong>.</p>
<p>If we fit this model with interaction terms, we get the following estimates:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="multiple.html#cb187-1"></a>lm.home3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>AnyFireplace<span class="op">*</span>Living.Area, <span class="dt">data =</span> homes)</span>
<span id="cb187-2"><a href="multiple.html#cb187-2"></a><span class="kw">summary</span>(lm.home3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ AnyFireplace * Living.Area, data = homes)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -241710  -39588   -7821   28480  542055 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   40901.294   8234.665   4.967 7.47e-07 ***
## AnyFireplaceTRUE             -37610.413  11024.853  -3.411 0.000661 ***
## Living.Area                      92.364      5.412  17.066  &lt; 2e-16 ***
## AnyFireplaceTRUE:Living.Area     26.852      6.459   4.157 3.38e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 68760 on 1724 degrees of freedom
## Multiple R-squared:  0.513,	Adjusted R-squared:  0.5122 
## F-statistic: 605.4 on 3 and 1724 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>Homes with fireplace (indicator = 1):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hbox{Predicted Price} &amp;= 40901.29 + -37610.41 \times 1 + 92.36391 \times \hbox{Living.Area} + 26.85 \times \hbox{Living.Area} \times 1 \\
&amp; = \$3,290.88 + \$119.21 \times \hbox{Living.Area}
\end{align*}
\]</span></p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="multiple.html#cb189-1"></a><span class="fl">40901.29</span> <span class="op">+</span><span class="st"> </span><span class="fl">-37610.41</span><span class="op">*</span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 3290.88</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="multiple.html#cb191-1"></a><span class="fl">92.36391</span> <span class="op">+</span><span class="st"> </span><span class="fl">26.85</span><span class="op">*</span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 119.2139</code></pre>
<ul>
<li>Homes without fireplace (indicator = 0):</li>
</ul>
<p><span class="math display">\[
\begin{align*}
\hbox{Predicted Price} &amp;= 40901.29 + -37610.41 \times 0 + 92.36391 \times \hbox{Living.Area} + 26.85 \times \hbox{Living.Area} \times 0 \\
&amp;= \$40,901.29 + \$92.36 \times \hbox{Living.Area}
\end{align*}
\]</span></p>
<ul>
<li><span class="math inline">\(\$-37610.41\)</span> is the difference in the estimated intercepts between homes with and without a fireplace</li>
<li><span class="math inline">\(\$26.85\)</span> is the difference in the estimated slopes between homes with and without a fireplace</li>
</ul>
</div>
<div id="is-the-difference-real" class="section level3">
<h3><span class="header-section-number">3.9.4</span> Is the Difference Real?</h3>
<p>We could ask: is there <em>really</em> a difference in the slopes for Living Area and Price between homes with and without a fireplace?</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="multiple.html#cb193-1"></a><span class="kw">summary</span>(lm.home3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ AnyFireplace * Living.Area, data = homes)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -241710  -39588   -7821   28480  542055 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   40901.294   8234.665   4.967 7.47e-07 ***
## AnyFireplaceTRUE             -37610.413  11024.853  -3.411 0.000661 ***
## Living.Area                      92.364      5.412  17.066  &lt; 2e-16 ***
## AnyFireplaceTRUE:Living.Area     26.852      6.459   4.157 3.38e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 68760 on 1724 degrees of freedom
## Multiple R-squared:  0.513,	Adjusted R-squared:  0.5122 
## F-statistic: 605.4 on 3 and 1724 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>If we ask ourselves this question, we are assuming a few things:</p>
<ol style="list-style-type: decimal">
<li><p>We would like to make a general statement about a <strong>target population of interest</strong>.</p></li>
<li><p>We don’t have data for everyone in our population (we don’t have a <strong>census</strong>).</p></li>
<li><p>Depending on who <strong>randomly</strong> ends up in our <strong>sample</strong>, the relationship may change a bit.</p></li>
<li><p>We want to know how much the relationship may change based on <strong>sampling variation.</strong></p></li>
</ol>
<ul>
<li>Let’s treat our sample (of size <span class="math inline">\(n\)</span>) as a ‘fake’ population (we don’t have the full population but if the sample is representative, then it will be a good proxy).
<ul>
<li>Randomly resample from our sample (with replacement) a new sample of size <span class="math inline">\(n\)</span></li>
</ul></li>
<li>Estimate the least squares regression line.</li>
<li>Repeat.</li>
</ul>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="multiple.html#cb195-1"></a><span class="kw">set.seed</span>(<span class="dv">333</span>) <span class="co">## Setting the seed ensures that our results are reproducible</span></span>
<span id="cb195-2"><a href="multiple.html#cb195-2"></a><span class="co">## Repeat the sampling and regression modeling 1000 times</span></span>
<span id="cb195-3"><a href="multiple.html#cb195-3"></a>boot &lt;-<span class="st"> </span><span class="kw">do</span>(<span class="dv">1000</span>)<span class="op">*</span><span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>Living.Area<span class="op">*</span>AnyFireplace, <span class="dt">data =</span> <span class="kw">resample</span>(homes))</span>
<span id="cb195-4"><a href="multiple.html#cb195-4"></a></span>
<span id="cb195-5"><a href="multiple.html#cb195-5"></a><span class="co">## Plot the distribution of the 1000 slope differences</span></span>
<span id="cb195-6"><a href="multiple.html#cb195-6"></a>boot <span class="op">%&gt;%</span></span>
<span id="cb195-7"><a href="multiple.html#cb195-7"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Living.Area.AnyFireplaceTRUE)) <span class="op">+</span></span>
<span id="cb195-8"><a href="multiple.html#cb195-8"></a><span class="st">    </span><span class="kw">geom_histogram</span>() <span class="op">+</span></span>
<span id="cb195-9"><a href="multiple.html#cb195-9"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Bootstrap Difference in Slopes&#39;</span>) <span class="op">+</span></span>
<span id="cb195-10"><a href="multiple.html#cb195-10"></a><span class="st">    </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>We see that if we were to have a slightly different sample (drawn from our “fake” population), then the difference in the slope could be as long as 0 and as large as 50.</p>
<p>This process of resampling from the sample is called <strong>Bootstrapping</strong> and it is used to:</p>
<ol style="list-style-type: decimal">
<li>Measure the variability in the estimates (here we are interested in the difference in slopes) between random samples and</li>
<li>Provide an interval of plausible values for the estimate (the difference in slopes here).</li>
</ol>
<p>Let’s first look at the variability of the difference in slopes across the bootstrap samples. The standard deviation of the bootstrap estimates will be similar to the <code>Std. Error</code> from the linear model output.</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="multiple.html#cb196-1"></a>boot <span class="op">%&gt;%</span></span>
<span id="cb196-2"><a href="multiple.html#cb196-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="kw">sd</span>(Living.Area.AnyFireplaceTRUE)) <span class="co">#this is going to be of similar magnitude (not exactly the same) to the Std. Error for the Living.Area.AnyFireplaceTRUE coefficient in output</span></span></code></pre></div>
<pre><code>##   sd(Living.Area.AnyFireplaceTRUE)
## 1                         9.332937</code></pre>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="multiple.html#cb198-1"></a><span class="kw">summary</span>(lm.home3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ AnyFireplace * Living.Area, data = homes)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -241710  -39588   -7821   28480  542055 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   40901.294   8234.665   4.967 7.47e-07 ***
## AnyFireplaceTRUE             -37610.413  11024.853  -3.411 0.000661 ***
## Living.Area                      92.364      5.412  17.066  &lt; 2e-16 ***
## AnyFireplaceTRUE:Living.Area     26.852      6.459   4.157 3.38e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 68760 on 1724 degrees of freedom
## Multiple R-squared:  0.513,	Adjusted R-squared:  0.5122 
## F-statistic: 605.4 on 3 and 1724 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This standard deviation is somewhat close to the <span class="math inline">\(6.459\)</span> for Living.Area.AnyFireplaceTRUE coefficient in the Std. Error column of the <code>summary(lm.home3)</code> output above.</p>
<p>To get an interval of plausible values for the difference in the slopes, we look at the histogram and take the middle 95%. The lower end will be the 2.5th percentile and the upper end will be the 97.5th percentile.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="multiple.html#cb200-1"></a>boot <span class="op">%&gt;%</span></span>
<span id="cb200-2"><a href="multiple.html#cb200-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">lower =</span> <span class="kw">quantile</span>(Living.Area.AnyFireplaceTRUE, <span class="fl">0.025</span>), <span class="dt">upper =</span> <span class="kw">quantile</span>(Living.Area.AnyFireplaceTRUE, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      lower    upper
## 1 7.686552 45.43513</code></pre>
<div class="reflect">
<p>
Based on this evidence, do you think it is possible that the slopes are the same for the two types of homes (with and without fireplaces)? How would you justify your answer? Consider the plausible values of the difference in slopes given by the interval above.
</p>
</div>
</div>
<div id="redundant" class="section level3">
<h3><span class="header-section-number">3.9.5</span> Redundancy and Multicollinearity</h3>
<p>Beyond fireplaces and living area, there are other characteristics that may impact the price of a home. Typically, homes for sale are advertised with the square footage, the number of bedrooms, and the number of bathrooms in addition to the total number of rooms in the house. In general, we’d expect a positive relationship between each of these and the home price. Let’s fit a model with those four explanatory variables.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="multiple.html#cb202-1"></a>lm.home4 &lt;-<span class="st"> </span>homes <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>( <span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>Living.Area <span class="op">+</span><span class="st"> </span>Bedrooms <span class="op">+</span><span class="st"> </span>Bathrooms <span class="op">+</span><span class="st"> </span>Rooms))</span>
<span id="cb202-2"><a href="multiple.html#cb202-2"></a><span class="kw">summary</span>(lm.home4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ Living.Area + Bedrooms + Bathrooms + Rooms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -245900  -40224   -7387   28090  533563 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  18937.389   6871.239   2.756  0.00591 ** 
## Living.Area     98.572      4.932  19.985  &lt; 2e-16 ***
## Bedrooms    -16922.902   2832.244  -5.975 2.79e-09 ***
## Bathrooms    26038.557   3543.063   7.349 3.07e-13 ***
## Rooms         3400.172   1109.628   3.064  0.00222 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 67390 on 1723 degrees of freedom
## Multiple R-squared:  0.5325,	Adjusted R-squared:  0.5314 
## F-statistic: 490.6 on 4 and 1723 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>If we look at the estimates of the slope coefficients, are you surprised to see that <code>Bedrooms</code> has a negative slope estimate?</p>
<p>Remember, the coefficients are the change in the expected price for a 1 unit change in that variable, keeping all other variables fixed. Is it <em>possible</em> to keep <code>Rooms</code> fixed while adding an additional <code>Bedroom</code>? In practice, that would mean you need to convert an existing room to a <code>Bedroom</code>. Let’s look at a scatterplot between these two variables. If it not realistic or possible to fix one variable while increasing the other, we cannot interpret the slope coefficients in the standard way.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="multiple.html#cb204-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb204-2"><a href="multiple.html#cb204-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Rooms, <span class="dt">y =</span> Bedrooms)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb204-3"><a href="multiple.html#cb204-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb204-4"><a href="multiple.html#cb204-4"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="multiple.html#cb205-1"></a>homes <span class="op">%&gt;%</span></span>
<span id="cb205-2"><a href="multiple.html#cb205-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="kw">cor</span>(Rooms,Bedrooms))</span></code></pre></div>
<pre><code>##   cor(Rooms, Bedrooms)
## 1            0.6718633</code></pre>
<p>These two characteristics are positively correlated because the count of <code>Rooms</code> is defined as the number of <code>Bedrooms</code> plus the number of other rooms in the house. So they contain some similar information about a home. Knowing how many rooms a house has, you can could have a pretty good guess at how many bedrooms it has. Maybe one of these variables is a bit redundant.</p>
<p>Let’s take another view at this model with an <strong>Added Variable Plot</strong>. Here are a few characteristics of an added variable plot.</p>
<ol style="list-style-type: decimal">
<li>We have one scatterplot per <span class="math inline">\(X\)</span> explanatory variable in the model.</li>
<li>For each scatterplot, the values on the x and y axes are residuals from two different models, both of which we have not directly fit.</li>
</ol>
<p><em>What are these models?</em></p>
<ul>
<li>For the y-axes, the model that is fit is a multiple linear regression model for <span class="math inline">\(E[Y |\hbox{ all other }X\hbox{ variables except }X_j]\)</span>. The residuals from this model encode the variation and information about <span class="math inline">\(Y\)</span> that is left unexplained by other <span class="math inline">\(X\)</span> variables.</li>
<li>For the x-axes, the model that is fit is a multiple linear regression model for <span class="math inline">\(E[X_j | \hbox{ all other }X\hbox{ variables except }X_j]\)</span>. The residuals from this model encode the variation and information about <span class="math inline">\(X_j\)</span> that is left unexplained by other <span class="math inline">\(X\)</span> variables. In other words, the unique information the <span class="math inline">\(X_j\)</span> has that is not contained in the other <span class="math inline">\(X\)</span> variables.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>The slope of the line in each scatterplot is equal to the estimated slope coefficient for that variable in the model you fit.</li>
</ol>
<p>If we look at the example below, we see a fairly strong positive relationship in the first (upper left) scatterplot. What we can conclude is that living area has quite a bit of unique information not contained in <code>Bedrooms</code>, <code>Rooms</code>, and <code>Bathrooms</code> that can explain variation in home price. Another way to phrase this is that after adjusting for or accounting for the number of <code>Bedrooms</code>, <code>Rooms</code>, and <code>Bathrooms</code>, we see a moderately strong positive linear relationship between <code>Living.Area</code> and <code>Price</code>.</p>
<p>In the second (upper right) scatterplot, we see a weak negative relationship between <code>Bedrooms</code> and <code>Price</code> after account for the square footage of the living area, the number of bathrooms, and the number of rooms. So there isn’t much unique information about bedrooms that can help explain the variation in price that isn’t already contained in <code>Rooms</code>, <code>Bathrooms</code>, and <code>Living.Area</code>. Since the slope is negative, we might conclude that converting an existing room (keeping square footage and number of rooms fixed) to a bedroom slightly decreases the estimated expected home price.</p>
<p>With <code>Rooms</code> and <code>Bathrooms</code>, we see positive but weak relationships after accounting for the other explanatory variables. In fact, the slope of these lines are equal to the estimated coefficients from the summary.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="multiple.html#cb207-1"></a><span class="kw">source</span>(<span class="st">&#39;Data/ggavplot.R&#39;</span>)</span>
<span id="cb207-2"><a href="multiple.html#cb207-2"></a><span class="kw">ggAVPLOTS</span>(lm.home4)</span></code></pre></div>
<p><img src="03-linear-regression_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>If we were to remove <code>Rooms</code> as it seems to be redundant, containing similar information as <code>Bedrooms</code>, we get a bit different estimated slope coefficients.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="multiple.html#cb208-1"></a>lm.home5 &lt;-<span class="st"> </span>homes <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>( <span class="kw">lm</span>(Price <span class="op">~</span><span class="st"> </span>Living.Area <span class="op">+</span><span class="st"> </span>Bedrooms <span class="op">+</span><span class="st"> </span>Bathrooms ))</span>
<span id="cb208-2"><a href="multiple.html#cb208-2"></a><span class="kw">summary</span>(lm.home5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ Living.Area + Bedrooms + Bathrooms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -239040  -40340   -7775   28308  540154 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  21323.089   6843.580   3.116  0.00186 ** 
## Living.Area    105.204      4.443  23.679  &lt; 2e-16 ***
## Bedrooms    -13702.463   2636.422  -5.197 2.26e-07 ***
## Bathrooms    25912.548   3551.434   7.296 4.49e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 67550 on 1724 degrees of freedom
## Multiple R-squared:  0.5299,	Adjusted R-squared:  0.5291 
## F-statistic: 647.8 on 3 and 1724 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>So should Rooms stay in the model or come out?</em></p>
<p>Does adding <code>Rooms</code> help explain more variation in home <code>Price</code>?</p>
<p>We can see that WITH <code>Rooms</code>, we explained 53.2% of the variation in home <code>Price</code>.</p>
<p>We can see that WITHOUT <code>Rooms</code>, we explained 52.9% of the variation in home <code>Price</code>.</p>
<p>So <code>Rooms</code> doesn’t add a lot to the explanatory power of the model.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="multiple.html#cb210-1"></a><span class="kw">glance</span>(lm.home4)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 12
##   r.squared adj.r.squared  sigma statistic   p.value    df  logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.532         0.531 67388.      491. 1.58e-282     4 -21662. 43335. 43368.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="multiple.html#cb212-1"></a><span class="kw">glance</span>(lm.home5)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 12
##   r.squared adj.r.squared  sigma statistic   p.value    df  logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.530         0.529 67552.      648. 6.15e-282     3 -21666. 43343. 43370.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p><strong>Fun Fact</strong>: Adding an explanatory variable <span class="math inline">\(X\)</span> to the model will always increase R-squared or keep it the same.</p>
<p>In general, we’d like the most simple (least number of <span class="math inline">\(X\)</span> variables) that does a good job for our goals. If R-squared never goes down when you add an explanatory variable, we need a different tool to help us decide whether to add a variable.</p>
<p>Remember that
<span class="math display">\[R^2 = 1 - \frac{SSE}{SSTO} = \%\hbox{ of variation in Y explained by model}\]</span></p>
<p><strong>Adjusted R-Squared</strong> is a slightly adjusted version of R-squared that takes into account the number of <span class="math inline">\(X\)</span> variables in the model, denoted as <span class="math inline">\(k\)</span>. It is calculated as</p>
<p><span class="math display">\[R^2_{adj} = 1 - \frac{SSE/(n-k-1)}{SSTO/(n-1)}\]</span></p>
<p>It does NOT have the interpretation of “% of variation explained…” but it can be used to help us decide whether a variable is redundant or whether we should keep it in the model. The adjusted R-squared for these two models are 0.531 (with Rooms) and 0.529 (without Rooms). This is a judgment call that you as the data analyst makes and this is one tool to help you make the decision. See the next section for more tools to help you decide.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="conditions-for-linear-regression-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="selecting-a-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-linear-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
