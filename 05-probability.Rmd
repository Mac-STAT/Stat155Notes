
```{r setup5, echo=FALSE}
library(stringr)
library(infer)
library(nycflights13)
library(broom)
library(dplyr)
library(ggplot2)
library(stringr)
library(rvest)
library(mosaicData) 
library(ggmosaic)
library(NHANES)
library(mosaic)
knitr::opts_chunk$set(echo = FALSE)
```

# Randomness and Probability

Recall the model we built to predict home price as a function of square footage and fireplaces. 

```{r echo=TRUE}
homes %>%
    ggplot(aes(x = Living.Area, y = Price, color = AnyFireplace)) + 
    geom_point() +
    theme_minimal()
```

To allow for different slopes among home with and without a fireplace, we used an interaction term between Living.Area and AnyFireplace. Based on our sample, we observed a difference in the slopes of $26.85 per square foot. But is this true for the larger population of homes? Does each square footage worth exactly \$27 more, on average, in homes with a fireplace than in homes without a fireplace?

```{r echo=TRUE}
lm.home3 <- lm(Price ~ AnyFireplace*Living.Area, data = homes)
tidy(lm.home3)
```

Probably not. In fact, our sample may be just one random sample from the larger population of homes in up state New York. If we had gotten a slightly different sample of homes, then we would have different estimates of each of these estimates. We explored this variation in Chapter 4 using bootstrapping. 


This chapter briefly discusses the theory of formal probability so that we have terminology and basic concepts to understand and discuss random events.This framework provides a way of thinking about **uncertainty,** **random variability**, and **average behavior in the long run.**

A **random process** or **random event** is an process/event that is not and cannot be made exact such that the outcome can not be accurately determined. Examples range from the outcome of flipping a coin to model parameters that are estimated using a randomly selected sample. 

We've used the term "chances" up until now and we defined that the chance of an event is between 0 and 1. We are now going to use "probability" as an equivalent word for "chance". Thus, the probability of an event will be between 0 and 1.  

For a much more in-depth discussion of probability, take MATH 354 (Probability). 


##Three Types of Probability

```{block type='reflect'}
What is the probability of getting a 1 from a six-sided die? Consider how do you know that. How can you justify that number?
```

There are three types of probability.

1. **Empirical Probability:** If you could repeat a random process over and over again, we'd get a sense of the possible outcomes and their associated probabilities by calculating their relative frequency in the long run. If you repeatedly tossed a die, then the relative frequency of 1's after tossing the die MANY times would be the empirical probability. If you repeatedly got a sample of 100 people, the relative frequency of estimated odds ratios below 1 would be the empirical probability of getting an odds ratio below 1. 

2. **Theoretical Probability:** If you don't have time to toss a die a million times, you could calculate probabilities based on mathematical theory and assumptions. You would assume that each side is equally likely to land up, thus the chance of getting a 1, is 1/6 for a six-sided die. 

```{block type='reflect'}
What is the probability you'll get an A in this class? What does that number represent? How can you justify that number?
```

3. **Subjective Probability:** If you use a number between 0 and 1 (100%) to reflect your uncertainty in an outcome (rather than based on empirical evidence or mathematical theory), then you are using subjective probability.

In this class, we'll focus on theoretical and empirical probability. In particular, we will use computational tools to estimate empirical probabilities using simulations (such as bootstrapping and randomization tests) and mathematical tools to estimate theoretical probabilities. 

##Probability Rules

In theoretical probability, we need to define a few terms and set some rules (known as axioms).

The **sample space,**  $S$, is the set of all possible outcomes of a random process.

- Example: If you flip two coins (one side Heads and one side Tails), then the sample space contains four possible outcomes: Heads and Heads (HH), Heads and Tails (HT), Tails and Heads (TH), and Tails and Tails (TT), $S = \{HH,HT,TH,TT\}$.

A subset of outcomes is called an **event**, $A$. 

- Example: If you flip two coins, an event $A$ could be that exactly one of the coins land Heads, $A = \{HT,TH\}$.

For events $A$ and $B$ and sample space $S$, the probability of an event $A$, notated as $P(A)$, follows the rules below:

- Rule 1: $0\leq P(A)\leq 1$ (probability has to be between 0 and 1)
- Rule 2: $P(S) = 1$ (one of the possible outcomes has to happen)
- Rule 3: $P(\text{not }A) = 1 - P(A)$ (if we know the chance of something happening, we also know that chance it doesn't happen)
- Rule 4: $P(A\text{ or }B) = P(A) + P(B)$ if $A$ and $B$ are disjoint events.
  - $A$ and $B$ are **disjoint** if $A$ occuring prevents $B$ from occurring (they both can't happen at the same time).
- Rule 4*: $P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and } B)$ in general
- Rule 5: $ P(A\text{ and }B) = P(A)\times P(B)$ if $A$ and $B$ are independent.
  - $A$ and $B$ are **independent** if $B$ occurring doesn't change the probability of $A$ occurring.
- Rule 5*: $P(A\text{ and }B) =P(A~|~B)P(B) = P(B~|~A)P(A)$.
  - The **conditional probability** of A **given** that event B occurs, $P(A~|~B)$, is equal to the probability of the joint event (A and B) divided by the probability of B.
$$P(A ~| ~B) = \frac{P(A \text{ and } B)}{P(B)} $$
  - Intuition: Given that $B$ happened, we focus on the subset of outcomes in $S$ in which $B$ occurs and then figure out what the chance of $A$ happening within that subset. 

For more details on theoretical probability, please see Appendex A. This material is optional but available for those of you who want to understand the mathematical reasoning behind the rest of the chapter. 

###Diagnotic Testing and Probability

Let's start by taking a moment to consider a recent article in the Washington Post (Link)[https://www.washingtonpost.com/news/posteverything/wp/2018/10/05/feature/doctors-are-surprisingly-bad-at-reading-lab-results-its-putting-us-all-at-risk/?utm_term=.73d08eefca3c]. Before you read the whole article, consider a question.

```{block, type="reflect"}
Say that Disease X has a prevalence of 1 in 1,000 (meaning that 1 out of every 1,000 people will have it), and the test to detect it has a false-positive rate of 5 percent (meaning 5 of every 100 subjects test positive for the ailment even though they don’t really have it). If a patient’s test result comes back positive, what are the chances that she actually has the disease?
```

If you said 95% chance, then you are wrong, but almost half of the doctors surveyed in 2014 thought the exact same thing.

Let's use those rules to get a sense of what the chance is. We want to know the chance they have the disease GIVEN they got a positive test result, $P(D | +)$ where $D$ stands for disease and $+$ stands for positive test result.

Based on the definition of conditional probability, we must consider only those that got a positive test result back and look at the proportion of them that have the disease. In mathematical notation, that is equal to

$$P(D | +) = \frac{P(D \text{ and } +)}{P(+)}$$

What information were we given again? 

- The prevalence of the disease is 1 in 1,000, so $P(D) = 1/1000$. Using Rule 3, the probability of no disease is $P(\text{ no }D) = 999/1000$. Think of 1000 people, 1 will actually have the disease and 999 won't have the disease.

- The false-positive rate is 5 percent, so given you don't have the disease, the chance of getting a false positive is $P(+ |\text{ no } D) = 0.05$. So of the 999 that don't have the disease, about 0.05*999 = 49.95 (about 50) of them will get a false positive test result.  

- While it is not stated, most medical tests have a fairly high accuracy in catching the disease so $P(+ | D) = 0.99$. Therefore, the 1 person who actually has the disease will most likely get a positive test result back (0.99*1 = 0.99). 

By the definition of conditional distribution, we consider only those with positive test results (50 who were are disease free and 1 who has the disease). So the chance of actually having the disease GIVEN a positive test result is 1/51 = 0.019.

In mathematical notation, that looks like this

$$P(D | +) = \frac{P(D \text{ and } +)}{P(+)}= \frac{P( + | D) P(D)}{P( + | D) P(D) + P( + | \text{ no }D) P(\text{no }D)} = \frac{0.99*1/1000}{0.99*1/1000 + 0.05*999/1000} = \frac{0.99*1}{0.99*1 + 0.05*999}$$

This is often called **Bayes Rule.** The important thing to consider is that what we condition on can make a big difference. 


Now, go take a few minutes and read the recent article in the Washington Post (Link)[https://www.washingtonpost.com/news/posteverything/wp/2018/10/05/feature/doctors-are-surprisingly-bad-at-reading-lab-results-its-putting-us-all-at-risk/?utm_term=.73d08eefca3c].

###Court Arguments and Probability

The concept of conditional probability also plays an important role in the judicial system in the U.S. We assume you are innocent until proven guilt. Thus, juries are instructed to consider the likelihood of the evidence, assuming the person on trial is innocent. In other words, consider the conditional probability: $P(\text{ evidence } | \text{ innocent })$.

Unfortunately, many prosecutor's try and make the wrong argument. They sometimes mistakenly try and argue that it is unlikely that a person is innocent given the evidence that is available, $P(\text{ innocent } | \text{ evidence })$. But this is not what the jury is supposed to consider, thus these types of arguments can lead to retrials.   

See more here: https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy



##Random Variable

With a basic understanding of theoretical probability rules, we can introduce the most important concept from probability. 

A **Random Variable** ($X$) is a real-valued function whose outcome we don't know beforehand. When considering data analysis and modeling, the random variables we will be thinking about will be estimate slopes, estimate odds ratios, etc. To establish our understanding, let's start with a simple example. 

You are going to flip a fair coin 3 times (the coin has 2-sides, we'll call one side Heads and the other Tails).

- Assume there are only 2 possible outcomes and P(Heads) = P(Tails) = 0.5 (can't land on its side).
- Below are three possible random variables based on the same random process (flipping a 2-sided coin 3 times):

- Example 1 - $X$: the number of heads in 3 coin flips
- What are the possible values of $X$? 0, 1, 2, or 3.

- Example 2 - Say I give you 3 dollars for each head
- $Y$: the amount of money won from 3 coin flips, $Y = 3*X$
- The possible values of $Y$ are 0, 3, 6, or 9.

- Example 3 - $Z$: the number of heads on the last flip of 3 coin flips
- The possible values are 0 or 1. 


###Probability Models

A **probability model** for random variable $X$ gives the possible values of $X$ and the associated probabilities. 

- What is the probability model for $X$: the number of heads in 3 coin flips?

$P(X = 0) = P(\text{three tails}) =  0.5^3$ (using Rule 5)
$P(X = 1) = P(\text{HTT or THT or TTH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(X = 2) = P(\text{HHT or HTH or THH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(X = 3) = P(\text{three heads}) = 0.5^3$ (using Rule 5)

- What is the probability model for $Y= 3*X$?

$P(Y = 0) = P(\text{three tails}) =  0.5^3$ (using Rule 5)
$P(Y = 3) = P(\text{HTT or THT or TTH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(Y = 6) = P(\text{HHT or HTH or THH }) = 3*0.5^3$ (using Rule 4 & 5)
$P(Y = 9) = P(\text{three heads}) = 0.5^3$ (using Rule 5)

- What about $Z$?

$P(Z = 0) = P(\text{HHT or TTT or HTT or THT}) =  4*0.5^3 = 0.5$ (using Rule 5)
$P(Z = 1) = P(\text{HHH or TTH or THH or HTH}) = 4*0.5^3 = 0.5$ (using Rule 4 & 5)


For most situations in our class, we won't be using the probability rules to calculate chances by hand. 

Rather, we will use a **named probability model** such that the we can calculate probabilities for particular values of the random variable using either a **probability mass function** (for a random variable with a finite number of possible values) or a **probability density function** (for a random variable with infinite number of possible values). 

In practice, we may be interested in the chance a random variable is within a range of values, such as $P(X < a)$ or $P(X > b)$ or $P(a < X < b)$.

If we have a probability mass function, we can add the probabilities that are within those ranges,

- $P(X < a) = \sum_{x < a}P(X = x)$
- $P(X > b) = \sum_{x > b}P(X = x)$
- $P(a < X < b) = \sum_{a < x < b}P(X = x)$

If we have a probability density function, then the probability of any one particular value is 0, so we find the area under the curve (defined by the probability density function) over the range,

INSERT GRAPHS for areas under curves of pdf





- Expected Value and Variance as concepts, not as theory
- Put in context of sampling variability (mean and sd of the sampling distribution) and variability from randomization assignment



##Bernoulli/Binomial

- Tie to Logistic regression
- E(x) = p or E(x) = np or E(x/n) = p
- tie to sampling variability and the disease we talk about previously
- show the pmf graphically (show what it does when n get large)

##Normal
- Many Normal curve (each with its own mean and sd)
- Area under curve as it relates to 68-95-99.7 rule
- relate to z-score
- Big IDEA: +- 2SD


##Sampling Distribution and CLT
- Connecting CLT (NORMAL) and bootstrapping
- SE (estimate of RV SD), z-scores ( value - E(X) / SE)




